{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary dependencies\n",
    "# We are using yahoo_fin module, it is essentially a Python scraper that extracts finance data from Yahoo Finance platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed, so we can get the same results after rerunning several times\n",
    "np.random.seed(314)\n",
    "tf.random.set_seed(314)\n",
    "random.seed(314)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, we need to write a function that downloads the dataset from the Internet and preprocess it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This function is long but handy, it accepts several arguments to be as flexible as possible:\n",
    "\n",
    "- The ticker argument is the ticker we want to load, for instance, you can use TSLA for Tesla stock market, AAPL for Apple and so on. It can also be a pandas Dataframe with the condition it includes the columns in feature_columns as well as date as index.\n",
    "- n_steps integer indicates the historical sequence length we want to use, some people call it the window size, recall that we are going to use a recurrent neural network, we need to feed in to the network a sequence data, choosing 50 means that we will use 50 days of stock prices to predict the next lookup time step.\n",
    "- scale is a boolean variable that indicates whether to scale prices from 0 to 1, we will set this to True as scaling high values from 0 to 1 will help the neural network to learn much faster and more effectively.\n",
    "- okup_step is the future lookup step to predict, the default is set to 1 (e.g next day). 15 means the next 15 days, and so on.\n",
    "- split_by_date is a boolean which indicates whether we split our training and testing sets by date, setting it to False means we randomly split the data into training and testing using sklearn's train_test_split() function. If it's True (the default), we split the data in date order.\n",
    "\n",
    "### We will be using all the features available in this dataset, which are the open, high, low, volume and adjusted close. Please check this tutorial to learn more what these indicators are.\n",
    "\n",
    "### The above function does the following:\n",
    "- First, it loads the dataset using stock_info.get_data() function in yahoo_fin module.\n",
    "- It adds the \"date\" column from the index if it doesn't exist, this will help us later to get the features of the testing set.\n",
    "- If the scale argument is passed as True, it will scale all the prices from 0 to 1 (including the volume) using the sklearn's MinMaxScaler class. Note that each column has its own scaler.\n",
    "- It then adds the future column which indicates the target values (the labels to predict, or the y's) by shifting the adjusted close column by lookup_step.\n",
    "- After that, it shuffles and splits the data to training and testing sets, and finally returns the result.\n",
    "\n",
    "### To understand the code even better, I highly suggest you to manually print the output variable (result) and see how the features and labels are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    # shuffle two arrays in the same way\n",
    "    state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(state)\n",
    "    np.random.shuffle(b)\n",
    "\n",
    "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True,\n",
    "                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
    "    \"\"\"\n",
    "    Loads data from Yahoo Finance source, as well as scaling, shuffling, normalizing and splitting.\n",
    "    Params:\n",
    "        ticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc.\n",
    "        n_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\n",
    "        scale (bool): whether to scale prices from 0 to 1, default is True\n",
    "        shuffle (bool): whether to shuffle the dataset (both training & testing), default is True\n",
    "        lookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\n",
    "        split_by_date (bool): whether we split the dataset into training/testing by date, setting it \n",
    "            to False will split datasets in a random way\n",
    "        test_size (float): ratio for test data, default is 0.2 (20% testing data)\n",
    "        feature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n",
    "    \"\"\"\n",
    "    # see if ticker is already a loaded stock from yahoo finance\n",
    "    if isinstance(ticker, str):\n",
    "        # load it from yahoo_fin library\n",
    "        df = si.get_data(ticker)\n",
    "    elif isinstance(ticker, pd.DataFrame):\n",
    "        # already loaded, use it directly\n",
    "        df = ticker\n",
    "    else:\n",
    "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
    "    # this will contain all the elements we want to return from this function\n",
    "    result = {}\n",
    "    # we will also return the original dataframe itself\n",
    "    result['df'] = df.copy()\n",
    "    # make sure that the passed feature_columns exist in the dataframe\n",
    "    for col in feature_columns:\n",
    "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "    # add date as a column\n",
    "    if \"date\" not in df.columns:\n",
    "        df[\"date\"] = df.index\n",
    "    if scale:\n",
    "        column_scaler = {}\n",
    "        # scale the data (prices) from 0 to 1\n",
    "        for column in feature_columns:\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "            column_scaler[column] = scaler\n",
    "        # add the MinMaxScaler instances to the result returned\n",
    "        result[\"column_scaler\"] = column_scaler\n",
    "    # add the target column (label) by shifting by `lookup_step`\n",
    "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
    "    # last `lookup_step` columns contains NaN in future column\n",
    "    # get them before droping NaNs\n",
    "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "    # drop NaNs\n",
    "    df.dropna(inplace=True)\n",
    "    sequence_data = []\n",
    "    sequences = deque(maxlen=n_steps)\n",
    "    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
    "        sequences.append(entry)\n",
    "        if len(sequences) == n_steps:\n",
    "            sequence_data.append([np.array(sequences), target])\n",
    "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
    "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n",
    "    # this last_sequence will be used to predict future stock prices that are not available in the dataset\n",
    "    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
    "    last_sequence = np.array(last_sequence).astype(np.float32)\n",
    "    # add to result\n",
    "    result['last_sequence'] = last_sequence\n",
    "    # construct the X's and y's\n",
    "    X, y = [], []\n",
    "    for seq, target in sequence_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    # convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    if split_by_date:\n",
    "        # split the dataset into training & testing sets by date (not randomly splitting)\n",
    "        train_samples = int((1 - test_size) * len(X))\n",
    "        result[\"X_train\"] = X[:train_samples]\n",
    "        result[\"y_train\"] = y[:train_samples]\n",
    "        result[\"X_test\"]  = X[train_samples:]\n",
    "        result[\"y_test\"]  = y[train_samples:]\n",
    "        if shuffle:\n",
    "            # shuffle the datasets for training (if shuffle parameter is set)\n",
    "            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
    "            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
    "    else:    \n",
    "        # split the dataset randomly\n",
    "        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n",
    "                                                                                test_size=test_size, shuffle=shuffle)\n",
    "    # get the list of test set dates\n",
    "    dates = result[\"X_test\"][:, -1, -1]\n",
    "    # retrieve test features from the original dataframe\n",
    "    result[\"test_df\"] = result[\"df\"].loc[dates]\n",
    "    # remove duplicated dates in the testing dataframe\n",
    "    result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n",
    "    # remove dates from the training/testing sets & convert to float32\n",
    "    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(sequence_length, n_features, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n",
    "        elif i == n_layers - 1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # add dropout after each layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So the below code is all about defining all the hyper parameters we gonna use, we explained some of them, while we didn't on the others:\n",
    "\n",
    "- TEST_SIZE: The testing set rate. For instance 0.2 means 20% of the total dataset.\n",
    "- FEATURE_COLUMNS: The features we gonna use to predict the next price value.\n",
    "- N_LAYERS: Number of RNN layers to use.\n",
    "- CELL: RNN cell to use, default is LSTM.\n",
    "- UNITS: Number of cell units.\n",
    "- DROPOUT: The dropout rate is the probability of not training a given node in a layer, where 0.0 means no dropout at all. This type of regularization can help the model to not overfit on our training data.\n",
    "- BIDIRECTIONAL: Whether to use bidirectional recurrent neural networks.\n",
    "- LOSS: Loss function to use for this regression problem, we're using Huber loss, you can use mean absolute error (mae) or mean squared error (mse) as well.\n",
    "- OPTIMIZER: Optimization algorithm to use, defaulting to Adam.\n",
    "- BATCH_SIZE: The number of data samples to use on each training iteration.\n",
    "- EPOCHS: The number of times that the learning algorithm will pass through the entire training dataset, we used 500 here, but try to increase it further more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 50\n",
    "\n",
    "# Lookup step, 1 is the next day\n",
    "LOOKUP_STEP = 15\n",
    "\n",
    "# whether to scale feature columns & output price as well\n",
    "SCALE = True\n",
    "scale_str = f\"sc-{int(SCALE)}\"\n",
    "\n",
    "# whether to shuffle the dataset\n",
    "SHUFFLE = True\n",
    "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
    "\n",
    "# whether to split the training/testing set by date\n",
    "SPLIT_BY_DATE = False\n",
    "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
    "\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "# features to use\n",
    "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
    "\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "### model parameters\n",
    "N_LAYERS = 2\n",
    "\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "\n",
    "# 256 LSTM neurons\n",
    "UNITS = 256\n",
    "\n",
    "# 40% dropout\n",
    "DROPOUT = 0.4\n",
    "\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = False\n",
    "\n",
    "### training parameters\n",
    "# mean absolute error loss\n",
    "# LOSS = \"mae\"\n",
    "# huber loss\n",
    "LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 500\n",
    "\n",
    "# Amazon stock market\n",
    "ticker = \"AMZN\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
    "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make folders for the 'results', 'logs', and 'data' before training begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create these folders if they does not exist\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, make function calls to implement the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "75/75 [==============================] - 27s 332ms/step - loss: 0.0039 - mean_absolute_error: 0.0378 - val_loss: 1.3144e-04 - val_mean_absolute_error: 0.0082\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00013, saving model to results\\2021-04-16_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 2/500\n",
      "75/75 [==============================] - 23s 300ms/step - loss: 4.1157e-04 - mean_absolute_error: 0.0136 - val_loss: 2.6275e-04 - val_mean_absolute_error: 0.0129\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00013\n",
      "Epoch 3/500\n",
      "75/75 [==============================] - 23s 305ms/step - loss: 5.4804e-04 - mean_absolute_error: 0.0160 - val_loss: 1.8139e-04 - val_mean_absolute_error: 0.0130\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00013\n",
      "Epoch 4/500\n",
      "75/75 [==============================] - 29s 388ms/step - loss: 3.7801e-04 - mean_absolute_error: 0.0138 - val_loss: 1.2379e-04 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00013 to 0.00012, saving model to results\\2021-04-16_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 5/500\n",
      "75/75 [==============================] - 34s 449ms/step - loss: 3.9294e-04 - mean_absolute_error: 0.0134 - val_loss: 1.1921e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00012 to 0.00012, saving model to results\\2021-04-16_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 6/500\n",
      "75/75 [==============================] - 35s 463ms/step - loss: 3.7590e-04 - mean_absolute_error: 0.0128 - val_loss: 1.8870e-04 - val_mean_absolute_error: 0.0097\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00012\n",
      "Epoch 7/500\n",
      "75/75 [==============================] - 33s 437ms/step - loss: 4.1348e-04 - mean_absolute_error: 0.0150 - val_loss: 1.7155e-04 - val_mean_absolute_error: 0.0087\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00012\n",
      "Epoch 8/500\n",
      "75/75 [==============================] - 31s 407ms/step - loss: 3.6163e-04 - mean_absolute_error: 0.0129 - val_loss: 1.5415e-04 - val_mean_absolute_error: 0.0090\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00012\n",
      "Epoch 9/500\n",
      "75/75 [==============================] - 28s 378ms/step - loss: 3.5254e-04 - mean_absolute_error: 0.0130 - val_loss: 1.2574e-04 - val_mean_absolute_error: 0.0085\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00012\n",
      "Epoch 10/500\n",
      "75/75 [==============================] - 27s 366ms/step - loss: 3.3275e-04 - mean_absolute_error: 0.0127 - val_loss: 1.7628e-04 - val_mean_absolute_error: 0.0111\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00012\n",
      "Epoch 11/500\n",
      "75/75 [==============================] - 27s 365ms/step - loss: 4.7657e-04 - mean_absolute_error: 0.0146 - val_loss: 1.2256e-04 - val_mean_absolute_error: 0.0081\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00012\n",
      "Epoch 12/500\n",
      "75/75 [==============================] - 28s 381ms/step - loss: 5.5775e-04 - mean_absolute_error: 0.0161 - val_loss: 1.4032e-04 - val_mean_absolute_error: 0.0083\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00012\n",
      "Epoch 13/500\n",
      "75/75 [==============================] - 32s 433ms/step - loss: 3.7867e-04 - mean_absolute_error: 0.0139 - val_loss: 1.4448e-04 - val_mean_absolute_error: 0.0099\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00012\n",
      "Epoch 14/500\n",
      "75/75 [==============================] - 32s 425ms/step - loss: 3.3482e-04 - mean_absolute_error: 0.0132 - val_loss: 1.4873e-04 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00012\n",
      "Epoch 15/500\n",
      "75/75 [==============================] - 32s 433ms/step - loss: 3.3577e-04 - mean_absolute_error: 0.0128 - val_loss: 1.2090e-04 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00012\n",
      "Epoch 16/500\n",
      "75/75 [==============================] - 33s 442ms/step - loss: 3.8534e-04 - mean_absolute_error: 0.0137 - val_loss: 1.2837e-04 - val_mean_absolute_error: 0.0079\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00012\n",
      "Epoch 17/500\n",
      "75/75 [==============================] - 38s 502ms/step - loss: 3.6227e-04 - mean_absolute_error: 0.0131 - val_loss: 3.1572e-04 - val_mean_absolute_error: 0.0128\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00012\n",
      "Epoch 18/500\n",
      "75/75 [==============================] - 38s 503ms/step - loss: 4.4536e-04 - mean_absolute_error: 0.0149 - val_loss: 2.6590e-04 - val_mean_absolute_error: 0.0125\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00012\n",
      "Epoch 19/500\n",
      "75/75 [==============================] - 33s 437ms/step - loss: 3.1940e-04 - mean_absolute_error: 0.0126 - val_loss: 1.3921e-04 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00012\n",
      "Epoch 20/500\n",
      "75/75 [==============================] - 30s 401ms/step - loss: 3.1829e-04 - mean_absolute_error: 0.0131 - val_loss: 1.2072e-04 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00012\n",
      "Epoch 21/500\n",
      "75/75 [==============================] - 30s 400ms/step - loss: 3.3418e-04 - mean_absolute_error: 0.0130 - val_loss: 1.1923e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00012\n",
      "Epoch 22/500\n",
      "75/75 [==============================] - 30s 404ms/step - loss: 3.2931e-04 - mean_absolute_error: 0.0130 - val_loss: 1.2746e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00012\n",
      "Epoch 23/500\n",
      "75/75 [==============================] - 35s 462ms/step - loss: 3.2718e-04 - mean_absolute_error: 0.0134 - val_loss: 1.6295e-04 - val_mean_absolute_error: 0.0084\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00012\n",
      "Epoch 24/500\n",
      "75/75 [==============================] - 29s 388ms/step - loss: 3.0561e-04 - mean_absolute_error: 0.0128 - val_loss: 1.3759e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00012\n",
      "Epoch 25/500\n",
      "75/75 [==============================] - 29s 388ms/step - loss: 2.6629e-04 - mean_absolute_error: 0.0122 - val_loss: 1.3277e-04 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00012\n",
      "Epoch 26/500\n",
      "75/75 [==============================] - 29s 392ms/step - loss: 2.7964e-04 - mean_absolute_error: 0.0124 - val_loss: 1.1884e-04 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00012 to 0.00012, saving model to results\\2021-04-16_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 27/500\n",
      "75/75 [==============================] - 32s 422ms/step - loss: 3.0411e-04 - mean_absolute_error: 0.0125 - val_loss: 1.3117e-04 - val_mean_absolute_error: 0.0075\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00012\n",
      "Epoch 28/500\n",
      "75/75 [==============================] - 32s 430ms/step - loss: 3.7336e-04 - mean_absolute_error: 0.0139 - val_loss: 1.5400e-04 - val_mean_absolute_error: 0.0080\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00012\n",
      "Epoch 29/500\n",
      "75/75 [==============================] - 32s 422ms/step - loss: 3.9870e-04 - mean_absolute_error: 0.0148 - val_loss: 1.2336e-04 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00012\n",
      "Epoch 30/500\n",
      "75/75 [==============================] - 31s 417ms/step - loss: 3.5626e-04 - mean_absolute_error: 0.0139 - val_loss: 2.6877e-04 - val_mean_absolute_error: 0.0120\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00012\n",
      "Epoch 31/500\n",
      "75/75 [==============================] - 34s 457ms/step - loss: 3.0391e-04 - mean_absolute_error: 0.0132 - val_loss: 1.3793e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00012\n",
      "Epoch 32/500\n",
      "75/75 [==============================] - 38s 504ms/step - loss: 3.0150e-04 - mean_absolute_error: 0.0131 - val_loss: 1.9569e-04 - val_mean_absolute_error: 0.0098\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00012\n",
      "Epoch 33/500\n",
      "75/75 [==============================] - 33s 442ms/step - loss: 3.8957e-04 - mean_absolute_error: 0.0145 - val_loss: 3.5992e-04 - val_mean_absolute_error: 0.0133\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00012\n",
      "Epoch 34/500\n",
      "75/75 [==============================] - 32s 424ms/step - loss: 3.6507e-04 - mean_absolute_error: 0.0140 - val_loss: 1.7782e-04 - val_mean_absolute_error: 0.0087\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00012\n",
      "Epoch 35/500\n",
      "75/75 [==============================] - 31s 413ms/step - loss: 3.2114e-04 - mean_absolute_error: 0.0132 - val_loss: 1.5388e-04 - val_mean_absolute_error: 0.0088\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00012\n",
      "Epoch 36/500\n",
      "75/75 [==============================] - 31s 417ms/step - loss: 3.5387e-04 - mean_absolute_error: 0.0138 - val_loss: 1.6071e-04 - val_mean_absolute_error: 0.0086\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00012\n",
      "Epoch 37/500\n",
      "75/75 [==============================] - 32s 428ms/step - loss: 3.6710e-04 - mean_absolute_error: 0.0142 - val_loss: 1.3866e-04 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00012\n",
      "Epoch 38/500\n",
      "75/75 [==============================] - 35s 467ms/step - loss: 3.2619e-04 - mean_absolute_error: 0.0136 - val_loss: 1.8585e-04 - val_mean_absolute_error: 0.0089\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00012\n",
      "Epoch 39/500\n",
      "75/75 [==============================] - 38s 505ms/step - loss: 2.8610e-04 - mean_absolute_error: 0.0133 - val_loss: 1.1918e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00012\n",
      "Epoch 40/500\n",
      "75/75 [==============================] - 38s 514ms/step - loss: 3.1271e-04 - mean_absolute_error: 0.0133 - val_loss: 1.1578e-04 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00012 to 0.00012, saving model to results\\2021-04-16_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 41/500\n",
      "75/75 [==============================] - 41s 543ms/step - loss: 3.5127e-04 - mean_absolute_error: 0.0138 - val_loss: 1.6995e-04 - val_mean_absolute_error: 0.0100\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00012\n",
      "Epoch 42/500\n",
      "75/75 [==============================] - 33s 436ms/step - loss: 3.3984e-04 - mean_absolute_error: 0.0141 - val_loss: 1.3823e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.00012\n",
      "Epoch 43/500\n",
      "75/75 [==============================] - 32s 425ms/step - loss: 3.0557e-04 - mean_absolute_error: 0.0131 - val_loss: 1.2216e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00012\n",
      "Epoch 44/500\n",
      "75/75 [==============================] - 32s 421ms/step - loss: 3.1653e-04 - mean_absolute_error: 0.0136 - val_loss: 1.4664e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00012\n",
      "Epoch 45/500\n",
      "75/75 [==============================] - 31s 419ms/step - loss: 2.3781e-04 - mean_absolute_error: 0.0125 - val_loss: 1.2441e-04 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00012\n",
      "Epoch 46/500\n",
      "75/75 [==============================] - 31s 419ms/step - loss: 2.9901e-04 - mean_absolute_error: 0.0134 - val_loss: 2.0892e-04 - val_mean_absolute_error: 0.0094\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00012\n",
      "Epoch 47/500\n",
      "75/75 [==============================] - 31s 418ms/step - loss: 2.9276e-04 - mean_absolute_error: 0.0132 - val_loss: 1.4673e-04 - val_mean_absolute_error: 0.0075\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00012\n",
      "Epoch 48/500\n",
      "75/75 [==============================] - 31s 420ms/step - loss: 3.0353e-04 - mean_absolute_error: 0.0134 - val_loss: 1.9269e-04 - val_mean_absolute_error: 0.0080\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00012\n",
      "Epoch 49/500\n",
      "75/75 [==============================] - 32s 433ms/step - loss: 3.1708e-04 - mean_absolute_error: 0.0135 - val_loss: 1.4350e-04 - val_mean_absolute_error: 0.0083\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00012\n",
      "Epoch 50/500\n",
      "75/75 [==============================] - 31s 417ms/step - loss: 2.6747e-04 - mean_absolute_error: 0.0126 - val_loss: 1.2822e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00012\n",
      "Epoch 51/500\n",
      "75/75 [==============================] - 33s 439ms/step - loss: 3.3562e-04 - mean_absolute_error: 0.0143 - val_loss: 1.1938e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.00012\n",
      "Epoch 52/500\n",
      "75/75 [==============================] - 34s 448ms/step - loss: 2.9515e-04 - mean_absolute_error: 0.0132 - val_loss: 1.7577e-04 - val_mean_absolute_error: 0.0085\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.00012\n",
      "Epoch 53/500\n",
      "75/75 [==============================] - 40s 530ms/step - loss: 2.5063e-04 - mean_absolute_error: 0.0123 - val_loss: 1.5336e-04 - val_mean_absolute_error: 0.0089\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.00012\n",
      "Epoch 54/500\n",
      "75/75 [==============================] - 33s 441ms/step - loss: 3.1507e-04 - mean_absolute_error: 0.0137 - val_loss: 1.4930e-04 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.00012\n",
      "Epoch 55/500\n",
      "75/75 [==============================] - 33s 442ms/step - loss: 2.6706e-04 - mean_absolute_error: 0.0127 - val_loss: 1.6160e-04 - val_mean_absolute_error: 0.0089\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.00012\n",
      "Epoch 56/500\n",
      "75/75 [==============================] - 31s 410ms/step - loss: 3.1427e-04 - mean_absolute_error: 0.0136 - val_loss: 1.1248e-04 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00012 to 0.00011, saving model to results\\2021-04-16_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 57/500\n",
      "75/75 [==============================] - 30s 402ms/step - loss: 2.7389e-04 - mean_absolute_error: 0.0130 - val_loss: 1.1308e-04 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.00011\n",
      "Epoch 58/500\n",
      "75/75 [==============================] - 31s 414ms/step - loss: 2.4333e-04 - mean_absolute_error: 0.0125 - val_loss: 1.1499e-04 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00011\n",
      "Epoch 59/500\n",
      "75/75 [==============================] - 31s 412ms/step - loss: 2.9454e-04 - mean_absolute_error: 0.0136 - val_loss: 1.3889e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.00011\n",
      "Epoch 60/500\n",
      "75/75 [==============================] - 30s 402ms/step - loss: 2.7553e-04 - mean_absolute_error: 0.0130 - val_loss: 1.1006e-04 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00011 to 0.00011, saving model to results\\2021-04-16_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 61/500\n",
      "75/75 [==============================] - 30s 405ms/step - loss: 2.3775e-04 - mean_absolute_error: 0.0126 - val_loss: 1.1670e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.00011\n",
      "Epoch 62/500\n",
      "75/75 [==============================] - 30s 404ms/step - loss: 2.6729e-04 - mean_absolute_error: 0.0127 - val_loss: 1.2515e-04 - val_mean_absolute_error: 0.0088\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.00011\n",
      "Epoch 63/500\n",
      "75/75 [==============================] - 30s 395ms/step - loss: 2.8298e-04 - mean_absolute_error: 0.0134 - val_loss: 1.2865e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.00011\n",
      "Epoch 64/500\n",
      "75/75 [==============================] - 29s 393ms/step - loss: 2.6093e-04 - mean_absolute_error: 0.0126 - val_loss: 1.1762e-04 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.00011\n",
      "Epoch 65/500\n",
      "75/75 [==============================] - 30s 398ms/step - loss: 2.3145e-04 - mean_absolute_error: 0.0125 - val_loss: 1.1246e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.00011\n",
      "Epoch 66/500\n",
      "75/75 [==============================] - 32s 422ms/step - loss: 2.3838e-04 - mean_absolute_error: 0.0125 - val_loss: 1.6311e-04 - val_mean_absolute_error: 0.0082\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.00011\n",
      "Epoch 67/500\n",
      "75/75 [==============================] - 32s 431ms/step - loss: 2.8336e-04 - mean_absolute_error: 0.0132 - val_loss: 1.2796e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.00011\n",
      "Epoch 68/500\n",
      "75/75 [==============================] - 32s 426ms/step - loss: 2.9380e-04 - mean_absolute_error: 0.0133 - val_loss: 1.1086e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.00011\n",
      "Epoch 69/500\n",
      "75/75 [==============================] - 32s 424ms/step - loss: 2.4978e-04 - mean_absolute_error: 0.0126 - val_loss: 1.1502e-04 - val_mean_absolute_error: 0.0072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00069: val_loss did not improve from 0.00011\n",
      "Epoch 70/500\n",
      "75/75 [==============================] - 32s 428ms/step - loss: 2.9292e-04 - mean_absolute_error: 0.0136 - val_loss: 1.3096e-04 - val_mean_absolute_error: 0.0086\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.00011\n",
      "Epoch 71/500\n",
      "75/75 [==============================] - 32s 433ms/step - loss: 2.3892e-04 - mean_absolute_error: 0.0127 - val_loss: 1.5108e-04 - val_mean_absolute_error: 0.0085\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.00011\n",
      "Epoch 72/500\n",
      "75/75 [==============================] - 33s 445ms/step - loss: 2.5290e-04 - mean_absolute_error: 0.0131 - val_loss: 1.0126e-04 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.00011 to 0.00010, saving model to results\\2021-04-16_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 73/500\n",
      "75/75 [==============================] - 32s 433ms/step - loss: 2.4390e-04 - mean_absolute_error: 0.0127 - val_loss: 1.3658e-04 - val_mean_absolute_error: 0.0087\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.00010\n",
      "Epoch 74/500\n",
      "75/75 [==============================] - 30s 402ms/step - loss: 2.7979e-04 - mean_absolute_error: 0.0137 - val_loss: 1.1948e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.00010\n",
      "Epoch 75/500\n",
      "75/75 [==============================] - 30s 398ms/step - loss: 2.4661e-04 - mean_absolute_error: 0.0129 - val_loss: 1.1519e-04 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.00010\n",
      "Epoch 76/500\n",
      "75/75 [==============================] - 42s 553ms/step - loss: 2.4942e-04 - mean_absolute_error: 0.0128 - val_loss: 1.0211e-04 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.00010\n",
      "Epoch 77/500\n",
      "75/75 [==============================] - 28s 375ms/step - loss: 2.5164e-04 - mean_absolute_error: 0.0131 - val_loss: 1.3149e-04 - val_mean_absolute_error: 0.0084\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.00010\n",
      "Epoch 78/500\n",
      "75/75 [==============================] - 28s 377ms/step - loss: 2.4132e-04 - mean_absolute_error: 0.0125 - val_loss: 1.2563e-04 - val_mean_absolute_error: 0.0083\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.00010\n",
      "Epoch 79/500\n",
      "75/75 [==============================] - 28s 372ms/step - loss: 2.2400e-04 - mean_absolute_error: 0.0125 - val_loss: 2.2357e-04 - val_mean_absolute_error: 0.0116\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.00010\n",
      "Epoch 80/500\n",
      "75/75 [==============================] - 28s 370ms/step - loss: 2.8004e-04 - mean_absolute_error: 0.0133 - val_loss: 1.1512e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.00010\n",
      "Epoch 81/500\n",
      "75/75 [==============================] - 28s 370ms/step - loss: 2.4343e-04 - mean_absolute_error: 0.0128 - val_loss: 1.0390e-04 - val_mean_absolute_error: 0.0080\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.00010\n",
      "Epoch 82/500\n",
      "75/75 [==============================] - 28s 375ms/step - loss: 2.6251e-04 - mean_absolute_error: 0.0129 - val_loss: 1.4278e-04 - val_mean_absolute_error: 0.0079\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.00010\n",
      "Epoch 83/500\n",
      "75/75 [==============================] - 28s 372ms/step - loss: 2.8861e-04 - mean_absolute_error: 0.0131 - val_loss: 1.1605e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.00010\n",
      "Epoch 84/500\n",
      "75/75 [==============================] - 27s 365ms/step - loss: 2.5939e-04 - mean_absolute_error: 0.0133 - val_loss: 9.8620e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.00010 to 0.00010, saving model to results\\2021-04-16_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 85/500\n",
      "75/75 [==============================] - 26s 353ms/step - loss: 2.4647e-04 - mean_absolute_error: 0.0126 - val_loss: 1.1086e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.00010\n",
      "Epoch 86/500\n",
      "75/75 [==============================] - 26s 341ms/step - loss: 2.2748e-04 - mean_absolute_error: 0.0123 - val_loss: 1.2607e-04 - val_mean_absolute_error: 0.0075\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.00010\n",
      "Epoch 87/500\n",
      "75/75 [==============================] - 25s 336ms/step - loss: 3.0597e-04 - mean_absolute_error: 0.0139 - val_loss: 1.0825e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.00010\n",
      "Epoch 88/500\n",
      "75/75 [==============================] - 25s 339ms/step - loss: 2.3393e-04 - mean_absolute_error: 0.0124 - val_loss: 1.0545e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.00010\n",
      "Epoch 89/500\n",
      "75/75 [==============================] - 26s 348ms/step - loss: 1.9884e-04 - mean_absolute_error: 0.0120 - val_loss: 1.3182e-04 - val_mean_absolute_error: 0.0083\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.00010\n",
      "Epoch 90/500\n",
      "75/75 [==============================] - 28s 378ms/step - loss: 2.4305e-04 - mean_absolute_error: 0.0127 - val_loss: 1.1204e-04 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.00010\n",
      "Epoch 91/500\n",
      "75/75 [==============================] - 27s 359ms/step - loss: 2.2778e-04 - mean_absolute_error: 0.0126 - val_loss: 1.1335e-04 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.00010\n",
      "Epoch 92/500\n",
      "75/75 [==============================] - 32s 429ms/step - loss: 2.4440e-04 - mean_absolute_error: 0.0126 - val_loss: 1.1211e-04 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.00010\n",
      "Epoch 93/500\n",
      "75/75 [==============================] - 38s 512ms/step - loss: 2.1550e-04 - mean_absolute_error: 0.0120 - val_loss: 1.0027e-04 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.00010\n",
      "Epoch 94/500\n",
      "75/75 [==============================] - 29s 383ms/step - loss: 2.6003e-04 - mean_absolute_error: 0.0125 - val_loss: 1.1031e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.00010\n",
      "Epoch 95/500\n",
      "75/75 [==============================] - 29s 384ms/step - loss: 2.2776e-04 - mean_absolute_error: 0.0122 - val_loss: 1.1565e-04 - val_mean_absolute_error: 0.0081\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.00010\n",
      "Epoch 96/500\n",
      "75/75 [==============================] - 28s 375ms/step - loss: 2.1107e-04 - mean_absolute_error: 0.0121 - val_loss: 1.0433e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.00010\n",
      "Epoch 97/500\n",
      "75/75 [==============================] - 28s 380ms/step - loss: 2.0760e-04 - mean_absolute_error: 0.0121 - val_loss: 1.0870e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.00010\n",
      "Epoch 98/500\n",
      "75/75 [==============================] - 30s 402ms/step - loss: 2.2269e-04 - mean_absolute_error: 0.0123 - val_loss: 1.3542e-04 - val_mean_absolute_error: 0.0094\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.00010\n",
      "Epoch 99/500\n",
      "75/75 [==============================] - 32s 424ms/step - loss: 2.5034e-04 - mean_absolute_error: 0.0129 - val_loss: 1.0342e-04 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.00010\n",
      "Epoch 100/500\n",
      "75/75 [==============================] - 32s 429ms/step - loss: 2.4045e-04 - mean_absolute_error: 0.0123 - val_loss: 9.6124e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.00010 to 0.00010, saving model to results\\2021-04-16_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 101/500\n",
      "75/75 [==============================] - 32s 434ms/step - loss: 2.3435e-04 - mean_absolute_error: 0.0128 - val_loss: 1.6597e-04 - val_mean_absolute_error: 0.0088\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.00010\n",
      "Epoch 102/500\n",
      "75/75 [==============================] - 33s 436ms/step - loss: 2.3606e-04 - mean_absolute_error: 0.0126 - val_loss: 9.6282e-05 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.00010\n",
      "Epoch 103/500\n",
      "75/75 [==============================] - 31s 419ms/step - loss: 2.4122e-04 - mean_absolute_error: 0.0126 - val_loss: 9.9953e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.00010\n",
      "Epoch 104/500\n",
      "75/75 [==============================] - 30s 395ms/step - loss: 2.0897e-04 - mean_absolute_error: 0.0119 - val_loss: 1.8884e-04 - val_mean_absolute_error: 0.0104\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.00010\n",
      "Epoch 105/500\n",
      "75/75 [==============================] - 29s 388ms/step - loss: 2.5478e-04 - mean_absolute_error: 0.0132 - val_loss: 1.1108e-04 - val_mean_absolute_error: 0.0082\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.00010\n",
      "Epoch 106/500\n",
      "75/75 [==============================] - 29s 392ms/step - loss: 2.1649e-04 - mean_absolute_error: 0.0123 - val_loss: 1.0557e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.00010\n",
      "Epoch 107/500\n",
      "75/75 [==============================] - 29s 394ms/step - loss: 2.4516e-04 - mean_absolute_error: 0.0124 - val_loss: 1.0142e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.00010\n",
      "Epoch 108/500\n",
      "75/75 [==============================] - 29s 391ms/step - loss: 2.4293e-04 - mean_absolute_error: 0.0127 - val_loss: 9.3263e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.00010 to 0.00009, saving model to results\\2021-04-16_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 109/500\n",
      "75/75 [==============================] - 30s 406ms/step - loss: 2.3079e-04 - mean_absolute_error: 0.0122 - val_loss: 1.4250e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.00009\n",
      "Epoch 110/500\n",
      "75/75 [==============================] - 30s 404ms/step - loss: 2.5881e-04 - mean_absolute_error: 0.0126 - val_loss: 1.0490e-04 - val_mean_absolute_error: 0.0084\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.00009\n",
      "Epoch 111/500\n",
      "75/75 [==============================] - 29s 394ms/step - loss: 2.3625e-04 - mean_absolute_error: 0.0128 - val_loss: 1.5861e-04 - val_mean_absolute_error: 0.0092\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.00009\n",
      "Epoch 112/500\n",
      "75/75 [==============================] - 29s 388ms/step - loss: 2.0660e-04 - mean_absolute_error: 0.0122 - val_loss: 9.9361e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.00009\n",
      "Epoch 113/500\n",
      "75/75 [==============================] - 852s 12s/step - loss: 2.3157e-04 - mean_absolute_error: 0.0124 - val_loss: 1.4111e-04 - val_mean_absolute_error: 0.0079\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.00009\n",
      "Epoch 114/500\n",
      "75/75 [==============================] - 24s 327ms/step - loss: 2.2666e-04 - mean_absolute_error: 0.0122 - val_loss: 1.3616e-04 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.00009\n",
      "Epoch 115/500\n",
      "75/75 [==============================] - 21s 284ms/step - loss: 2.2712e-04 - mean_absolute_error: 0.0124 - val_loss: 9.8699e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.00009\n",
      "Epoch 116/500\n",
      "75/75 [==============================] - 20s 269ms/step - loss: 2.1974e-04 - mean_absolute_error: 0.0123 - val_loss: 1.1714e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.00009\n",
      "Epoch 117/500\n",
      "75/75 [==============================] - 21s 276ms/step - loss: 2.2485e-04 - mean_absolute_error: 0.0123 - val_loss: 1.0083e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.00009\n",
      "Epoch 118/500\n",
      "75/75 [==============================] - 21s 276ms/step - loss: 1.8684e-04 - mean_absolute_error: 0.0114 - val_loss: 9.8315e-05 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.00009\n",
      "Epoch 119/500\n",
      "75/75 [==============================] - 21s 274ms/step - loss: 2.1424e-04 - mean_absolute_error: 0.0120 - val_loss: 9.8254e-05 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.00009\n",
      "Epoch 120/500\n",
      "75/75 [==============================] - 22s 297ms/step - loss: 1.9048e-04 - mean_absolute_error: 0.0114 - val_loss: 1.1336e-04 - val_mean_absolute_error: 0.0079\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.00009\n",
      "Epoch 121/500\n",
      "75/75 [==============================] - 25s 339ms/step - loss: 2.4285e-04 - mean_absolute_error: 0.0125 - val_loss: 9.1843e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.00009 to 0.00009, saving model to results\\2021-04-16_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 122/500\n",
      "75/75 [==============================] - 25s 340ms/step - loss: 2.2320e-04 - mean_absolute_error: 0.0119 - val_loss: 1.2060e-04 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.00009\n",
      "Epoch 123/500\n",
      "75/75 [==============================] - 24s 316ms/step - loss: 2.1910e-04 - mean_absolute_error: 0.0119 - val_loss: 1.6479e-04 - val_mean_absolute_error: 0.0090\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.00009\n",
      "Epoch 124/500\n",
      "75/75 [==============================] - 22s 299ms/step - loss: 2.2059e-04 - mean_absolute_error: 0.0125 - val_loss: 1.0397e-04 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.00009\n",
      "Epoch 125/500\n",
      "75/75 [==============================] - 22s 292ms/step - loss: 2.1856e-04 - mean_absolute_error: 0.0122 - val_loss: 1.2081e-04 - val_mean_absolute_error: 0.0079\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.00009\n",
      "Epoch 126/500\n",
      "75/75 [==============================] - 25s 337ms/step - loss: 2.2354e-04 - mean_absolute_error: 0.0120 - val_loss: 8.9736e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.00009 to 0.00009, saving model to results\\2021-04-16_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 127/500\n",
      "75/75 [==============================] - 26s 342ms/step - loss: 2.4337e-04 - mean_absolute_error: 0.0121 - val_loss: 9.0686e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.00009\n",
      "Epoch 128/500\n",
      "75/75 [==============================] - 26s 341ms/step - loss: 2.2373e-04 - mean_absolute_error: 0.0122 - val_loss: 9.8849e-05 - val_mean_absolute_error: 0.0075\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.00009\n",
      "Epoch 129/500\n",
      "75/75 [==============================] - 24s 327ms/step - loss: 2.1868e-04 - mean_absolute_error: 0.0122 - val_loss: 9.9312e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.00009\n",
      "Epoch 130/500\n",
      "75/75 [==============================] - 23s 312ms/step - loss: 1.9624e-04 - mean_absolute_error: 0.0116 - val_loss: 9.2433e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.00009\n",
      "Epoch 131/500\n",
      "75/75 [==============================] - 25s 336ms/step - loss: 1.8438e-04 - mean_absolute_error: 0.0113 - val_loss: 1.2917e-04 - val_mean_absolute_error: 0.0080\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.00009\n",
      "Epoch 132/500\n",
      "75/75 [==============================] - 26s 346ms/step - loss: 2.5204e-04 - mean_absolute_error: 0.0127 - val_loss: 8.9485e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.00009 to 0.00009, saving model to results\\2021-04-16_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 133/500\n",
      "75/75 [==============================] - 26s 345ms/step - loss: 2.2727e-04 - mean_absolute_error: 0.0122 - val_loss: 9.4435e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.00009\n",
      "Epoch 134/500\n",
      "75/75 [==============================] - 25s 334ms/step - loss: 2.3121e-04 - mean_absolute_error: 0.0123 - val_loss: 1.4175e-04 - val_mean_absolute_error: 0.0086\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.00009\n",
      "Epoch 135/500\n",
      "75/75 [==============================] - 25s 337ms/step - loss: 2.3137e-04 - mean_absolute_error: 0.0126 - val_loss: 1.0170e-04 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.00009\n",
      "Epoch 136/500\n",
      "75/75 [==============================] - 25s 336ms/step - loss: 2.3966e-04 - mean_absolute_error: 0.0128 - val_loss: 9.2590e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.00009\n",
      "Epoch 137/500\n",
      "75/75 [==============================] - 25s 335ms/step - loss: 1.9347e-04 - mean_absolute_error: 0.0114 - val_loss: 1.3227e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.00009\n",
      "Epoch 138/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 25s 335ms/step - loss: 2.4522e-04 - mean_absolute_error: 0.0125 - val_loss: 8.8825e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.00009 to 0.00009, saving model to results\\2021-04-16_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 139/500\n",
      "75/75 [==============================] - 4720s 64s/step - loss: 1.9522e-04 - mean_absolute_error: 0.0116 - val_loss: 1.3523e-04 - val_mean_absolute_error: 0.0089\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.00009\n",
      "Epoch 140/500\n",
      "75/75 [==============================] - 22s 296ms/step - loss: 2.3145e-04 - mean_absolute_error: 0.0122 - val_loss: 1.0248e-04 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.00009\n",
      "Epoch 141/500\n",
      "75/75 [==============================] - 22s 299ms/step - loss: 2.1563e-04 - mean_absolute_error: 0.0119 - val_loss: 1.0289e-04 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.00009\n",
      "Epoch 142/500\n",
      "75/75 [==============================] - 23s 306ms/step - loss: 2.2968e-04 - mean_absolute_error: 0.0123 - val_loss: 9.9302e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.00009\n",
      "Epoch 143/500\n",
      "75/75 [==============================] - 23s 306ms/step - loss: 2.1378e-04 - mean_absolute_error: 0.0121 - val_loss: 9.0003e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.00009\n",
      "Epoch 144/500\n",
      "75/75 [==============================] - 23s 312ms/step - loss: 2.2087e-04 - mean_absolute_error: 0.0119 - val_loss: 9.5637e-05 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.00009\n",
      "Epoch 145/500\n",
      "75/75 [==============================] - 23s 309ms/step - loss: 2.1387e-04 - mean_absolute_error: 0.0119 - val_loss: 9.2105e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.00009\n",
      "Epoch 146/500\n",
      "75/75 [==============================] - 21s 283ms/step - loss: 2.2564e-04 - mean_absolute_error: 0.0120 - val_loss: 1.0063e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.00009\n",
      "Epoch 147/500\n",
      "75/75 [==============================] - 31s 422ms/step - loss: 2.2293e-04 - mean_absolute_error: 0.0120 - val_loss: 9.8244e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.00009\n",
      "Epoch 148/500\n",
      "75/75 [==============================] - 28s 368ms/step - loss: 2.2012e-04 - mean_absolute_error: 0.0121 - val_loss: 9.4507e-05 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.00009\n",
      "Epoch 149/500\n",
      "75/75 [==============================] - 26s 344ms/step - loss: 2.2422e-04 - mean_absolute_error: 0.0119 - val_loss: 9.2069e-05 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.00009\n",
      "Epoch 150/500\n",
      "75/75 [==============================] - 24s 326ms/step - loss: 2.3073e-04 - mean_absolute_error: 0.0122 - val_loss: 9.4372e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.00009\n",
      "Epoch 151/500\n",
      "75/75 [==============================] - 24s 320ms/step - loss: 2.1979e-04 - mean_absolute_error: 0.0120 - val_loss: 1.0282e-04 - val_mean_absolute_error: 0.0086\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.00009\n",
      "Epoch 152/500\n",
      "75/75 [==============================] - 26s 347ms/step - loss: 2.2498e-04 - mean_absolute_error: 0.0123 - val_loss: 9.3904e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.00009\n",
      "Epoch 153/500\n",
      "75/75 [==============================] - 29s 385ms/step - loss: 2.2200e-04 - mean_absolute_error: 0.0120 - val_loss: 1.0376e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.00009\n",
      "Epoch 154/500\n",
      "75/75 [==============================] - 32s 429ms/step - loss: 2.1924e-04 - mean_absolute_error: 0.0119 - val_loss: 9.8855e-05 - val_mean_absolute_error: 0.0081\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.00009\n",
      "Epoch 155/500\n",
      "75/75 [==============================] - 26s 348ms/step - loss: 2.1532e-04 - mean_absolute_error: 0.0120 - val_loss: 1.3595e-04 - val_mean_absolute_error: 0.0107\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.00009\n",
      "Epoch 156/500\n",
      "75/75 [==============================] - 26s 347ms/step - loss: 2.1641e-04 - mean_absolute_error: 0.0121 - val_loss: 1.1270e-04 - val_mean_absolute_error: 0.0090\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.00009\n",
      "Epoch 157/500\n",
      "75/75 [==============================] - 26s 348ms/step - loss: 2.1426e-04 - mean_absolute_error: 0.0118 - val_loss: 1.3007e-04 - val_mean_absolute_error: 0.0086\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.00009\n",
      "Epoch 158/500\n",
      "75/75 [==============================] - 26s 349ms/step - loss: 2.4338e-04 - mean_absolute_error: 0.0132 - val_loss: 9.1663e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.00009\n",
      "Epoch 159/500\n",
      "75/75 [==============================] - 26s 345ms/step - loss: 1.9801e-04 - mean_absolute_error: 0.0116 - val_loss: 1.1827e-04 - val_mean_absolute_error: 0.0082\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.00009\n",
      "Epoch 160/500\n",
      "75/75 [==============================] - 26s 346ms/step - loss: 2.1767e-04 - mean_absolute_error: 0.0120 - val_loss: 9.8739e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.00009\n",
      "Epoch 161/500\n",
      "75/75 [==============================] - 26s 348ms/step - loss: 2.0422e-04 - mean_absolute_error: 0.0117 - val_loss: 1.2897e-04 - val_mean_absolute_error: 0.0084\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.00009\n",
      "Epoch 162/500\n",
      "75/75 [==============================] - 27s 355ms/step - loss: 2.0824e-04 - mean_absolute_error: 0.0117 - val_loss: 9.7656e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.00009\n",
      "Epoch 163/500\n",
      "75/75 [==============================] - 28s 376ms/step - loss: 2.3582e-04 - mean_absolute_error: 0.0125 - val_loss: 1.1709e-04 - val_mean_absolute_error: 0.0086\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.00009\n",
      "Epoch 164/500\n",
      "75/75 [==============================] - 29s 388ms/step - loss: 2.3038e-04 - mean_absolute_error: 0.0123 - val_loss: 9.4374e-05 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.00009\n",
      "Epoch 165/500\n",
      "75/75 [==============================] - 29s 387ms/step - loss: 2.3520e-04 - mean_absolute_error: 0.0120 - val_loss: 1.1023e-04 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.00009\n",
      "Epoch 166/500\n",
      "75/75 [==============================] - 29s 386ms/step - loss: 2.3344e-04 - mean_absolute_error: 0.0119 - val_loss: 1.0280e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.00009\n",
      "Epoch 167/500\n",
      "75/75 [==============================] - 29s 388ms/step - loss: 2.1363e-04 - mean_absolute_error: 0.0118 - val_loss: 9.3796e-05 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.00009\n",
      "Epoch 168/500\n",
      "75/75 [==============================] - 29s 387ms/step - loss: 1.9578e-04 - mean_absolute_error: 0.0114 - val_loss: 1.0810e-04 - val_mean_absolute_error: 0.0080\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.00009\n",
      "Epoch 169/500\n",
      "75/75 [==============================] - 30s 395ms/step - loss: 2.1204e-04 - mean_absolute_error: 0.0115 - val_loss: 1.1465e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.00009\n",
      "Epoch 170/500\n",
      "75/75 [==============================] - 29s 389ms/step - loss: 2.2409e-04 - mean_absolute_error: 0.0121 - val_loss: 1.1314e-04 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.00009\n",
      "Epoch 171/500\n",
      "75/75 [==============================] - 30s 403ms/step - loss: 2.2078e-04 - mean_absolute_error: 0.0118 - val_loss: 1.0202e-04 - val_mean_absolute_error: 0.0079\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.00009\n",
      "Epoch 172/500\n",
      "75/75 [==============================] - 30s 401ms/step - loss: 2.1765e-04 - mean_absolute_error: 0.0118 - val_loss: 9.7286e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.00009\n",
      "Epoch 173/500\n",
      "75/75 [==============================] - 29s 390ms/step - loss: 2.4859e-04 - mean_absolute_error: 0.0127 - val_loss: 9.2600e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.00009\n",
      "Epoch 174/500\n",
      "75/75 [==============================] - 29s 382ms/step - loss: 2.1412e-04 - mean_absolute_error: 0.0119 - val_loss: 1.8256e-04 - val_mean_absolute_error: 0.0107\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.00009\n",
      "Epoch 175/500\n",
      "75/75 [==============================] - 29s 387ms/step - loss: 2.4573e-04 - mean_absolute_error: 0.0128 - val_loss: 1.4950e-04 - val_mean_absolute_error: 0.0085\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.00009\n",
      "Epoch 176/500\n",
      "75/75 [==============================] - 29s 385ms/step - loss: 2.0950e-04 - mean_absolute_error: 0.0118 - val_loss: 9.5650e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.00009\n",
      "Epoch 177/500\n",
      "75/75 [==============================] - 29s 382ms/step - loss: 2.0580e-04 - mean_absolute_error: 0.0115 - val_loss: 1.2859e-04 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.00009\n",
      "Epoch 178/500\n",
      "75/75 [==============================] - 29s 382ms/step - loss: 2.4484e-04 - mean_absolute_error: 0.0124 - val_loss: 1.2011e-04 - val_mean_absolute_error: 0.0088\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.00009\n",
      "Epoch 179/500\n",
      "75/75 [==============================] - 29s 387ms/step - loss: 2.3438e-04 - mean_absolute_error: 0.0123 - val_loss: 9.9934e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.00009\n",
      "Epoch 180/500\n",
      "75/75 [==============================] - 29s 390ms/step - loss: 1.8954e-04 - mean_absolute_error: 0.0115 - val_loss: 9.7349e-05 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.00009\n",
      "Epoch 181/500\n",
      "75/75 [==============================] - 29s 383ms/step - loss: 2.3978e-04 - mean_absolute_error: 0.0124 - val_loss: 9.7970e-05 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.00009\n",
      "Epoch 182/500\n",
      "75/75 [==============================] - 29s 385ms/step - loss: 2.1872e-04 - mean_absolute_error: 0.0118 - val_loss: 9.0839e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.00009\n",
      "Epoch 183/500\n",
      "75/75 [==============================] - 29s 387ms/step - loss: 2.1982e-04 - mean_absolute_error: 0.0119 - val_loss: 1.0014e-04 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.00009\n",
      "Epoch 184/500\n",
      "75/75 [==============================] - 29s 384ms/step - loss: 2.0564e-04 - mean_absolute_error: 0.0116 - val_loss: 1.0515e-04 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.00009\n",
      "Epoch 185/500\n",
      "75/75 [==============================] - 29s 384ms/step - loss: 1.9601e-04 - mean_absolute_error: 0.0113 - val_loss: 9.3116e-05 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.00009\n",
      "Epoch 186/500\n",
      "75/75 [==============================] - 30s 405ms/step - loss: 2.1322e-04 - mean_absolute_error: 0.0120 - val_loss: 1.2523e-04 - val_mean_absolute_error: 0.0081\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.00009\n",
      "Epoch 187/500\n",
      "75/75 [==============================] - 29s 383ms/step - loss: 2.2824e-04 - mean_absolute_error: 0.0121 - val_loss: 9.6910e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.00009\n",
      "Epoch 188/500\n",
      "75/75 [==============================] - 29s 385ms/step - loss: 2.1026e-04 - mean_absolute_error: 0.0115 - val_loss: 9.4436e-05 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.00009\n",
      "Epoch 189/500\n",
      "75/75 [==============================] - 29s 390ms/step - loss: 1.9521e-04 - mean_absolute_error: 0.0115 - val_loss: 9.3183e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.00009\n",
      "Epoch 190/500\n",
      "75/75 [==============================] - 29s 386ms/step - loss: 2.1660e-04 - mean_absolute_error: 0.0118 - val_loss: 9.7121e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.00009\n",
      "Epoch 191/500\n",
      "75/75 [==============================] - 29s 384ms/step - loss: 2.3374e-04 - mean_absolute_error: 0.0122 - val_loss: 9.7240e-05 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.00009\n",
      "Epoch 192/500\n",
      "75/75 [==============================] - 30s 395ms/step - loss: 1.9738e-04 - mean_absolute_error: 0.0114 - val_loss: 9.4503e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.00009\n",
      "Epoch 193/500\n",
      "75/75 [==============================] - 29s 381ms/step - loss: 2.1169e-04 - mean_absolute_error: 0.0119 - val_loss: 1.2515e-04 - val_mean_absolute_error: 0.0104\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.00009\n",
      "Epoch 194/500\n",
      "75/75 [==============================] - 29s 387ms/step - loss: 2.1786e-04 - mean_absolute_error: 0.0120 - val_loss: 9.5320e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.00009\n",
      "Epoch 195/500\n",
      "75/75 [==============================] - 30s 398ms/step - loss: 2.2708e-04 - mean_absolute_error: 0.0124 - val_loss: 9.4484e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.00009\n",
      "Epoch 196/500\n",
      "75/75 [==============================] - 29s 388ms/step - loss: 1.8829e-04 - mean_absolute_error: 0.0112 - val_loss: 1.0558e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.00009\n",
      "Epoch 197/500\n",
      "75/75 [==============================] - 29s 384ms/step - loss: 1.9302e-04 - mean_absolute_error: 0.0115 - val_loss: 1.2093e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.00009\n",
      "Epoch 198/500\n",
      "75/75 [==============================] - 29s 392ms/step - loss: 1.9965e-04 - mean_absolute_error: 0.0118 - val_loss: 1.1541e-04 - val_mean_absolute_error: 0.0081\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.00009\n",
      "Epoch 199/500\n",
      "75/75 [==============================] - 29s 388ms/step - loss: 2.0764e-04 - mean_absolute_error: 0.0117 - val_loss: 1.0615e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.00009\n",
      "Epoch 200/500\n",
      "75/75 [==============================] - 29s 388ms/step - loss: 2.0331e-04 - mean_absolute_error: 0.0115 - val_loss: 9.4300e-05 - val_mean_absolute_error: 0.0075\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.00009\n",
      "Epoch 201/500\n",
      "75/75 [==============================] - 29s 385ms/step - loss: 1.9720e-04 - mean_absolute_error: 0.0116 - val_loss: 1.0585e-04 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.00009\n",
      "Epoch 202/500\n",
      "75/75 [==============================] - 30s 403ms/step - loss: 2.0115e-04 - mean_absolute_error: 0.0115 - val_loss: 8.9686e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.00009\n",
      "Epoch 203/500\n",
      "75/75 [==============================] - 29s 389ms/step - loss: 1.8672e-04 - mean_absolute_error: 0.0113 - val_loss: 1.0910e-04 - val_mean_absolute_error: 0.0082\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.00009\n",
      "Epoch 204/500\n",
      "75/75 [==============================] - 30s 398ms/step - loss: 1.8044e-04 - mean_absolute_error: 0.0110 - val_loss: 1.1097e-04 - val_mean_absolute_error: 0.0089\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.00009\n",
      "Epoch 205/500\n",
      "75/75 [==============================] - 29s 388ms/step - loss: 1.9288e-04 - mean_absolute_error: 0.0114 - val_loss: 1.1127e-04 - val_mean_absolute_error: 0.0075\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.00009\n",
      "Epoch 206/500\n",
      "75/75 [==============================] - 29s 389ms/step - loss: 2.2631e-04 - mean_absolute_error: 0.0119 - val_loss: 9.2640e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.00009\n",
      "Epoch 207/500\n",
      "75/75 [==============================] - 29s 384ms/step - loss: 2.0170e-04 - mean_absolute_error: 0.0112 - val_loss: 1.0161e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.00009\n",
      "Epoch 208/500\n",
      "75/75 [==============================] - 29s 385ms/step - loss: 2.0504e-04 - mean_absolute_error: 0.0118 - val_loss: 1.0663e-04 - val_mean_absolute_error: 0.0075\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.00009\n",
      "Epoch 209/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 29s 384ms/step - loss: 2.1828e-04 - mean_absolute_error: 0.0119 - val_loss: 9.8295e-05 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.00009\n",
      "Epoch 210/500\n",
      "75/75 [==============================] - 29s 384ms/step - loss: 1.8243e-04 - mean_absolute_error: 0.0112 - val_loss: 9.1509e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.00009\n",
      "Epoch 211/500\n",
      "75/75 [==============================] - 29s 387ms/step - loss: 2.3706e-04 - mean_absolute_error: 0.0125 - val_loss: 9.7867e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.00009\n",
      "Epoch 212/500\n",
      "75/75 [==============================] - 29s 384ms/step - loss: 2.0938e-04 - mean_absolute_error: 0.0113 - val_loss: 9.5231e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.00009\n",
      "Epoch 213/500\n",
      "75/75 [==============================] - 29s 386ms/step - loss: 2.1128e-04 - mean_absolute_error: 0.0117 - val_loss: 9.4417e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.00009\n",
      "Epoch 214/500\n",
      "75/75 [==============================] - 29s 383ms/step - loss: 1.9005e-04 - mean_absolute_error: 0.0113 - val_loss: 9.7840e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.00009\n",
      "Epoch 215/500\n",
      "75/75 [==============================] - 29s 383ms/step - loss: 2.1974e-04 - mean_absolute_error: 0.0118 - val_loss: 9.4592e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.00009\n",
      "Epoch 216/500\n",
      "75/75 [==============================] - 29s 386ms/step - loss: 2.0805e-04 - mean_absolute_error: 0.0114 - val_loss: 9.7050e-05 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.00009\n",
      "Epoch 217/500\n",
      "75/75 [==============================] - 31s 411ms/step - loss: 2.0005e-04 - mean_absolute_error: 0.0115 - val_loss: 1.1078e-04 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.00009\n",
      "Epoch 218/500\n",
      "75/75 [==============================] - 30s 406ms/step - loss: 2.0982e-04 - mean_absolute_error: 0.0118 - val_loss: 1.0100e-04 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.00009\n",
      "Epoch 219/500\n",
      "75/75 [==============================] - 29s 391ms/step - loss: 1.9469e-04 - mean_absolute_error: 0.0113 - val_loss: 9.1850e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.00009\n",
      "Epoch 220/500\n",
      "75/75 [==============================] - 29s 392ms/step - loss: 2.0425e-04 - mean_absolute_error: 0.0115 - val_loss: 9.0300e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.00009\n",
      "Epoch 221/500\n",
      "75/75 [==============================] - 29s 387ms/step - loss: 1.8423e-04 - mean_absolute_error: 0.0114 - val_loss: 9.2817e-05 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.00009\n",
      "Epoch 222/500\n",
      "75/75 [==============================] - 29s 383ms/step - loss: 1.9986e-04 - mean_absolute_error: 0.0116 - val_loss: 9.1951e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.00009\n",
      "Epoch 223/500\n",
      "75/75 [==============================] - 29s 386ms/step - loss: 2.1132e-04 - mean_absolute_error: 0.0119 - val_loss: 9.8814e-05 - val_mean_absolute_error: 0.0083\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.00009\n",
      "Epoch 224/500\n",
      "75/75 [==============================] - 29s 384ms/step - loss: 2.0578e-04 - mean_absolute_error: 0.0116 - val_loss: 9.9202e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.00009\n",
      "Epoch 225/500\n",
      "75/75 [==============================] - 29s 386ms/step - loss: 2.0602e-04 - mean_absolute_error: 0.0115 - val_loss: 1.0247e-04 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.00009\n",
      "Epoch 226/500\n",
      "75/75 [==============================] - 29s 383ms/step - loss: 1.9471e-04 - mean_absolute_error: 0.0113 - val_loss: 9.4097e-05 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.00009\n",
      "Epoch 227/500\n",
      "75/75 [==============================] - 28s 380ms/step - loss: 2.1233e-04 - mean_absolute_error: 0.0120 - val_loss: 1.0399e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.00009\n",
      "Epoch 228/500\n",
      "75/75 [==============================] - 29s 381ms/step - loss: 2.2539e-04 - mean_absolute_error: 0.0120 - val_loss: 1.4171e-04 - val_mean_absolute_error: 0.0083\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.00009\n",
      "Epoch 229/500\n",
      "75/75 [==============================] - 29s 386ms/step - loss: 2.2925e-04 - mean_absolute_error: 0.0123 - val_loss: 1.4211e-04 - val_mean_absolute_error: 0.0086\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.00009\n",
      "Epoch 230/500\n",
      "75/75 [==============================] - 29s 384ms/step - loss: 2.3493e-04 - mean_absolute_error: 0.0125 - val_loss: 1.1069e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.00009\n",
      "Epoch 231/500\n",
      "75/75 [==============================] - 29s 383ms/step - loss: 2.0586e-04 - mean_absolute_error: 0.0114 - val_loss: 9.6078e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.00009\n",
      "Epoch 232/500\n",
      "75/75 [==============================] - 29s 381ms/step - loss: 2.0315e-04 - mean_absolute_error: 0.0117 - val_loss: 9.6977e-05 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.00009\n",
      "Epoch 233/500\n",
      "75/75 [==============================] - 29s 384ms/step - loss: 2.0822e-04 - mean_absolute_error: 0.0118 - val_loss: 9.2109e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.00009\n",
      "Epoch 234/500\n",
      "75/75 [==============================] - 29s 384ms/step - loss: 2.1140e-04 - mean_absolute_error: 0.0117 - val_loss: 9.9712e-05 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.00009\n",
      "Epoch 235/500\n",
      "75/75 [==============================] - 29s 387ms/step - loss: 2.3460e-04 - mean_absolute_error: 0.0118 - val_loss: 9.6172e-05 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.00009\n",
      "Epoch 236/500\n",
      "75/75 [==============================] - 36s 481ms/step - loss: 2.0994e-04 - mean_absolute_error: 0.0117 - val_loss: 1.0795e-04 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.00009\n",
      "Epoch 237/500\n",
      "75/75 [==============================] - 34s 453ms/step - loss: 2.1115e-04 - mean_absolute_error: 0.0115 - val_loss: 1.0901e-04 - val_mean_absolute_error: 0.0079\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.00009\n",
      "Epoch 238/500\n",
      "75/75 [==============================] - 28s 377ms/step - loss: 2.3632e-04 - mean_absolute_error: 0.0122 - val_loss: 9.3829e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.00009\n",
      "Epoch 239/500\n",
      "75/75 [==============================] - 27s 364ms/step - loss: 1.8026e-04 - mean_absolute_error: 0.0110 - val_loss: 9.8444e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.00009\n",
      "Epoch 240/500\n",
      "75/75 [==============================] - 26s 352ms/step - loss: 1.7207e-04 - mean_absolute_error: 0.0109 - val_loss: 1.0259e-04 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.00009\n",
      "Epoch 241/500\n",
      "75/75 [==============================] - 26s 342ms/step - loss: 2.0029e-04 - mean_absolute_error: 0.0117 - val_loss: 1.0435e-04 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.00009\n",
      "Epoch 242/500\n",
      "75/75 [==============================] - 25s 339ms/step - loss: 2.0834e-04 - mean_absolute_error: 0.0118 - val_loss: 9.6873e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.00009\n",
      "Epoch 243/500\n",
      "75/75 [==============================] - 25s 339ms/step - loss: 1.7202e-04 - mean_absolute_error: 0.0109 - val_loss: 9.7678e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.00009\n",
      "Epoch 244/500\n",
      "75/75 [==============================] - 25s 333ms/step - loss: 2.2510e-04 - mean_absolute_error: 0.0119 - val_loss: 9.1417e-05 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.00009\n",
      "Epoch 245/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 25s 332ms/step - loss: 1.8080e-04 - mean_absolute_error: 0.0110 - val_loss: 1.2105e-04 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.00009\n",
      "Epoch 246/500\n",
      "75/75 [==============================] - 25s 333ms/step - loss: 1.9900e-04 - mean_absolute_error: 0.0113 - val_loss: 9.2814e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.00009\n",
      "Epoch 247/500\n",
      "75/75 [==============================] - 25s 334ms/step - loss: 1.9628e-04 - mean_absolute_error: 0.0115 - val_loss: 9.5849e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.00009\n",
      "Epoch 248/500\n",
      "75/75 [==============================] - 25s 333ms/step - loss: 1.9436e-04 - mean_absolute_error: 0.0113 - val_loss: 9.1779e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.00009\n",
      "Epoch 249/500\n",
      "75/75 [==============================] - 25s 332ms/step - loss: 1.8862e-04 - mean_absolute_error: 0.0113 - val_loss: 9.8078e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.00009\n",
      "Epoch 250/500\n",
      "75/75 [==============================] - 25s 332ms/step - loss: 2.0226e-04 - mean_absolute_error: 0.0116 - val_loss: 9.1811e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.00009\n",
      "Epoch 251/500\n",
      "75/75 [==============================] - 25s 333ms/step - loss: 2.1364e-04 - mean_absolute_error: 0.0118 - val_loss: 9.3598e-05 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.00009\n",
      "Epoch 252/500\n",
      "75/75 [==============================] - 25s 335ms/step - loss: 2.0039e-04 - mean_absolute_error: 0.0117 - val_loss: 9.3443e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.00009\n",
      "Epoch 253/500\n",
      "75/75 [==============================] - 25s 337ms/step - loss: 1.9669e-04 - mean_absolute_error: 0.0116 - val_loss: 9.5753e-05 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.00009\n",
      "Epoch 254/500\n",
      "75/75 [==============================] - 25s 335ms/step - loss: 1.6995e-04 - mean_absolute_error: 0.0111 - val_loss: 9.7351e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.00009\n",
      "Epoch 255/500\n",
      "75/75 [==============================] - 25s 339ms/step - loss: 1.8661e-04 - mean_absolute_error: 0.0110 - val_loss: 8.9407e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.00009\n",
      "Epoch 256/500\n",
      "75/75 [==============================] - 25s 336ms/step - loss: 2.0655e-04 - mean_absolute_error: 0.0114 - val_loss: 9.0383e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.00009\n",
      "Epoch 257/500\n",
      "75/75 [==============================] - 25s 336ms/step - loss: 2.2551e-04 - mean_absolute_error: 0.0121 - val_loss: 9.0036e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.00009\n",
      "Epoch 258/500\n",
      "75/75 [==============================] - 25s 336ms/step - loss: 1.9076e-04 - mean_absolute_error: 0.0112 - val_loss: 9.7093e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.00009\n",
      "Epoch 259/500\n",
      "75/75 [==============================] - 25s 333ms/step - loss: 1.9547e-04 - mean_absolute_error: 0.0115 - val_loss: 9.4236e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.00009\n",
      "Epoch 260/500\n",
      "75/75 [==============================] - 27s 360ms/step - loss: 2.0111e-04 - mean_absolute_error: 0.0114 - val_loss: 1.1293e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.00009\n",
      "Epoch 261/500\n",
      "75/75 [==============================] - 29s 387ms/step - loss: 2.0436e-04 - mean_absolute_error: 0.0116 - val_loss: 9.8211e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.00009\n",
      "Epoch 262/500\n",
      "75/75 [==============================] - 26s 352ms/step - loss: 2.0928e-04 - mean_absolute_error: 0.0115 - val_loss: 8.9154e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.00009\n",
      "Epoch 263/500\n",
      "75/75 [==============================] - 27s 364ms/step - loss: 1.9854e-04 - mean_absolute_error: 0.0114 - val_loss: 9.0952e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.00009\n",
      "Epoch 264/500\n",
      "75/75 [==============================] - 29s 387ms/step - loss: 1.9643e-04 - mean_absolute_error: 0.0113 - val_loss: 9.0656e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.00009\n",
      "Epoch 265/500\n",
      "75/75 [==============================] - 30s 399ms/step - loss: 2.0327e-04 - mean_absolute_error: 0.0115 - val_loss: 9.7468e-05 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.00009\n",
      "Epoch 266/500\n",
      "75/75 [==============================] - 30s 397ms/step - loss: 2.0665e-04 - mean_absolute_error: 0.0115 - val_loss: 1.1604e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.00009\n",
      "Epoch 267/500\n",
      "75/75 [==============================] - 30s 396ms/step - loss: 1.9764e-04 - mean_absolute_error: 0.0115 - val_loss: 1.1779e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.00009\n",
      "Epoch 268/500\n",
      "75/75 [==============================] - 35s 472ms/step - loss: 2.0642e-04 - mean_absolute_error: 0.0116 - val_loss: 1.0013e-04 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.00009\n",
      "Epoch 269/500\n",
      "75/75 [==============================] - 40s 528ms/step - loss: 2.0211e-04 - mean_absolute_error: 0.0114 - val_loss: 1.0831e-04 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.00009\n",
      "Epoch 270/500\n",
      "75/75 [==============================] - 39s 527ms/step - loss: 1.8373e-04 - mean_absolute_error: 0.0111 - val_loss: 1.0398e-04 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.00009\n",
      "Epoch 271/500\n",
      "75/75 [==============================] - 35s 470ms/step - loss: 2.4542e-04 - mean_absolute_error: 0.0124 - val_loss: 9.0984e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.00009\n",
      "Epoch 272/500\n",
      "75/75 [==============================] - 35s 467ms/step - loss: 1.8867e-04 - mean_absolute_error: 0.0111 - val_loss: 9.2226e-05 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.00009\n",
      "Epoch 273/500\n",
      "75/75 [==============================] - 35s 467ms/step - loss: 1.9027e-04 - mean_absolute_error: 0.0113 - val_loss: 1.0558e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.00009\n",
      "Epoch 274/500\n",
      "75/75 [==============================] - 34s 456ms/step - loss: 1.9929e-04 - mean_absolute_error: 0.0114 - val_loss: 9.1040e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.00009\n",
      "Epoch 275/500\n",
      "75/75 [==============================] - 34s 454ms/step - loss: 1.7618e-04 - mean_absolute_error: 0.0110 - val_loss: 1.0981e-04 - val_mean_absolute_error: 0.0075\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.00009\n",
      "Epoch 276/500\n",
      "75/75 [==============================] - 34s 456ms/step - loss: 2.0190e-04 - mean_absolute_error: 0.0116 - val_loss: 9.3459e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.00009\n",
      "Epoch 277/500\n",
      "75/75 [==============================] - 41s 553ms/step - loss: 2.0148e-04 - mean_absolute_error: 0.0114 - val_loss: 1.0030e-04 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.00009\n",
      "Epoch 278/500\n",
      "75/75 [==============================] - 36s 487ms/step - loss: 2.3174e-04 - mean_absolute_error: 0.0120 - val_loss: 1.0092e-04 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.00009\n",
      "Epoch 279/500\n",
      "75/75 [==============================] - 35s 472ms/step - loss: 2.0842e-04 - mean_absolute_error: 0.0114 - val_loss: 9.3002e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.00009\n",
      "Epoch 280/500\n",
      "75/75 [==============================] - 34s 454ms/step - loss: 2.1144e-04 - mean_absolute_error: 0.0116 - val_loss: 9.5379e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.00009\n",
      "Epoch 281/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 35s 471ms/step - loss: 1.8206e-04 - mean_absolute_error: 0.0113 - val_loss: 8.9737e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.00009\n",
      "Epoch 282/500\n",
      "75/75 [==============================] - 34s 458ms/step - loss: 2.1138e-04 - mean_absolute_error: 0.0116 - val_loss: 1.0765e-04 - val_mean_absolute_error: 0.0075\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.00009\n",
      "Epoch 283/500\n",
      "75/75 [==============================] - 34s 458ms/step - loss: 1.7871e-04 - mean_absolute_error: 0.0110 - val_loss: 1.1889e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.00009\n",
      "Epoch 284/500\n",
      "75/75 [==============================] - 25s 331ms/step - loss: 2.2179e-04 - mean_absolute_error: 0.0120 - val_loss: 9.7128e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.00009\n",
      "Epoch 285/500\n",
      "75/75 [==============================] - 22s 287ms/step - loss: 2.2813e-04 - mean_absolute_error: 0.0118 - val_loss: 1.1239e-04 - val_mean_absolute_error: 0.0080\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.00009\n",
      "Epoch 286/500\n",
      "75/75 [==============================] - 25s 337ms/step - loss: 1.7983e-04 - mean_absolute_error: 0.0110 - val_loss: 1.0091e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.00009\n",
      "Epoch 287/500\n",
      "75/75 [==============================] - 35s 473ms/step - loss: 1.8553e-04 - mean_absolute_error: 0.0111 - val_loss: 1.2928e-04 - val_mean_absolute_error: 0.0080\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.00009\n",
      "Epoch 288/500\n",
      "75/75 [==============================] - 38s 500ms/step - loss: 2.0294e-04 - mean_absolute_error: 0.0115 - val_loss: 1.0991e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.00009\n",
      "Epoch 289/500\n",
      "75/75 [==============================] - 34s 458ms/step - loss: 1.7695e-04 - mean_absolute_error: 0.0108 - val_loss: 1.0528e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.00009\n",
      "Epoch 290/500\n",
      "75/75 [==============================] - 28s 374ms/step - loss: 2.1206e-04 - mean_absolute_error: 0.0117 - val_loss: 9.9686e-05 - val_mean_absolute_error: 0.0080\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.00009\n",
      "Epoch 291/500\n",
      "75/75 [==============================] - 26s 348ms/step - loss: 2.1594e-04 - mean_absolute_error: 0.0119 - val_loss: 8.9808e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.00009\n",
      "Epoch 292/500\n",
      "75/75 [==============================] - 26s 347ms/step - loss: 1.7144e-04 - mean_absolute_error: 0.0108 - val_loss: 1.0719e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.00009\n",
      "Epoch 293/500\n",
      "75/75 [==============================] - 26s 349ms/step - loss: 2.1013e-04 - mean_absolute_error: 0.0119 - val_loss: 1.0096e-04 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.00009\n",
      "Epoch 294/500\n",
      "75/75 [==============================] - 26s 346ms/step - loss: 2.0653e-04 - mean_absolute_error: 0.0115 - val_loss: 1.5765e-04 - val_mean_absolute_error: 0.0093\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.00009\n",
      "Epoch 295/500\n",
      "75/75 [==============================] - 26s 348ms/step - loss: 2.1608e-04 - mean_absolute_error: 0.0115 - val_loss: 9.3834e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.00009\n",
      "Epoch 296/500\n",
      "75/75 [==============================] - 27s 361ms/step - loss: 2.2860e-04 - mean_absolute_error: 0.0119 - val_loss: 9.8553e-05 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.00009\n",
      "Epoch 297/500\n",
      "75/75 [==============================] - 28s 375ms/step - loss: 2.0593e-04 - mean_absolute_error: 0.0118 - val_loss: 9.5462e-05 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.00009\n",
      "Epoch 298/500\n",
      "75/75 [==============================] - 29s 391ms/step - loss: 1.9748e-04 - mean_absolute_error: 0.0112 - val_loss: 9.3063e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.00009\n",
      "Epoch 299/500\n",
      "75/75 [==============================] - 30s 394ms/step - loss: 2.4845e-04 - mean_absolute_error: 0.0121 - val_loss: 9.1012e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.00009\n",
      "Epoch 300/500\n",
      "75/75 [==============================] - 30s 399ms/step - loss: 2.0746e-04 - mean_absolute_error: 0.0117 - val_loss: 9.0018e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.00009\n",
      "Epoch 301/500\n",
      "75/75 [==============================] - 29s 384ms/step - loss: 1.7614e-04 - mean_absolute_error: 0.0109 - val_loss: 9.0174e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.00009\n",
      "Epoch 302/500\n",
      "75/75 [==============================] - 29s 388ms/step - loss: 2.2056e-04 - mean_absolute_error: 0.0119 - val_loss: 1.0490e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.00009\n",
      "Epoch 303/500\n",
      "75/75 [==============================] - 29s 393ms/step - loss: 2.1165e-04 - mean_absolute_error: 0.0116 - val_loss: 1.2406e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.00009\n",
      "Epoch 304/500\n",
      "75/75 [==============================] - 29s 381ms/step - loss: 2.0477e-04 - mean_absolute_error: 0.0115 - val_loss: 8.7940e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00304: val_loss improved from 0.00009 to 0.00009, saving model to results\\2021-04-16_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 305/500\n",
      "75/75 [==============================] - 29s 383ms/step - loss: 1.9352e-04 - mean_absolute_error: 0.0111 - val_loss: 9.2161e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.00009\n",
      "Epoch 306/500\n",
      "75/75 [==============================] - 28s 375ms/step - loss: 2.1399e-04 - mean_absolute_error: 0.0116 - val_loss: 1.0520e-04 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.00009\n",
      "Epoch 307/500\n",
      "75/75 [==============================] - 29s 385ms/step - loss: 1.9118e-04 - mean_absolute_error: 0.0113 - val_loss: 1.0395e-04 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.00009\n",
      "Epoch 308/500\n",
      "75/75 [==============================] - 29s 384ms/step - loss: 1.9339e-04 - mean_absolute_error: 0.0111 - val_loss: 9.3833e-05 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.00009\n",
      "Epoch 309/500\n",
      "75/75 [==============================] - 29s 388ms/step - loss: 2.0663e-04 - mean_absolute_error: 0.0118 - val_loss: 1.1936e-04 - val_mean_absolute_error: 0.0079\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.00009\n",
      "Epoch 310/500\n",
      "75/75 [==============================] - 29s 388ms/step - loss: 2.0755e-04 - mean_absolute_error: 0.0117 - val_loss: 9.8327e-05 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.00009\n",
      "Epoch 311/500\n",
      "75/75 [==============================] - 29s 388ms/step - loss: 2.1265e-04 - mean_absolute_error: 0.0118 - val_loss: 8.5900e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00311: val_loss improved from 0.00009 to 0.00009, saving model to results\\2021-04-16_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 312/500\n",
      "75/75 [==============================] - 29s 390ms/step - loss: 1.8835e-04 - mean_absolute_error: 0.0113 - val_loss: 9.6057e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.00009\n",
      "Epoch 313/500\n",
      "75/75 [==============================] - 29s 390ms/step - loss: 1.8888e-04 - mean_absolute_error: 0.0113 - val_loss: 9.7382e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.00009\n",
      "Epoch 314/500\n",
      "75/75 [==============================] - 29s 386ms/step - loss: 1.8442e-04 - mean_absolute_error: 0.0110 - val_loss: 9.0475e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.00009\n",
      "Epoch 315/500\n",
      "75/75 [==============================] - 29s 389ms/step - loss: 1.9803e-04 - mean_absolute_error: 0.0114 - val_loss: 9.5571e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.00009\n",
      "Epoch 316/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 30s 401ms/step - loss: 1.8612e-04 - mean_absolute_error: 0.0113 - val_loss: 1.1100e-04 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.00009\n",
      "Epoch 317/500\n",
      "75/75 [==============================] - 35s 473ms/step - loss: 2.1213e-04 - mean_absolute_error: 0.0117 - val_loss: 1.2245e-04 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.00009\n",
      "Epoch 318/500\n",
      "75/75 [==============================] - 32s 426ms/step - loss: 2.3679e-04 - mean_absolute_error: 0.0123 - val_loss: 1.0029e-04 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.00009\n",
      "Epoch 319/500\n",
      "75/75 [==============================] - 29s 382ms/step - loss: 1.9602e-04 - mean_absolute_error: 0.0114 - val_loss: 1.3851e-04 - val_mean_absolute_error: 0.0092\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.00009\n",
      "Epoch 320/500\n",
      "75/75 [==============================] - 28s 377ms/step - loss: 2.0446e-04 - mean_absolute_error: 0.0113 - val_loss: 1.0958e-04 - val_mean_absolute_error: 0.0083\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.00009\n",
      "Epoch 321/500\n",
      "75/75 [==============================] - 26s 351ms/step - loss: 2.2251e-04 - mean_absolute_error: 0.0118 - val_loss: 9.1788e-05 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.00009\n",
      "Epoch 322/500\n",
      "75/75 [==============================] - 26s 350ms/step - loss: 2.0800e-04 - mean_absolute_error: 0.0119 - val_loss: 8.9888e-05 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.00009\n",
      "Epoch 323/500\n",
      "75/75 [==============================] - 29s 389ms/step - loss: 1.8264e-04 - mean_absolute_error: 0.0111 - val_loss: 9.6726e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.00009\n",
      "Epoch 324/500\n",
      "75/75 [==============================] - 26s 347ms/step - loss: 2.0535e-04 - mean_absolute_error: 0.0115 - val_loss: 8.9875e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.00009\n",
      "Epoch 325/500\n",
      "75/75 [==============================] - 26s 346ms/step - loss: 2.0842e-04 - mean_absolute_error: 0.0116 - val_loss: 1.1600e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.00009\n",
      "Epoch 326/500\n",
      "75/75 [==============================] - 27s 359ms/step - loss: 2.0027e-04 - mean_absolute_error: 0.0114 - val_loss: 9.0110e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.00009\n",
      "Epoch 327/500\n",
      "75/75 [==============================] - 28s 374ms/step - loss: 2.3098e-04 - mean_absolute_error: 0.0119 - val_loss: 8.9887e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.00009\n",
      "Epoch 328/500\n",
      "75/75 [==============================] - 30s 399ms/step - loss: 1.9503e-04 - mean_absolute_error: 0.0113 - val_loss: 1.1938e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.00009\n",
      "Epoch 329/500\n",
      "75/75 [==============================] - 30s 407ms/step - loss: 2.1967e-04 - mean_absolute_error: 0.0116 - val_loss: 1.0578e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.00009\n",
      "Epoch 330/500\n",
      "75/75 [==============================] - 29s 393ms/step - loss: 1.9125e-04 - mean_absolute_error: 0.0114 - val_loss: 1.0245e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.00009\n",
      "Epoch 331/500\n",
      "75/75 [==============================] - 30s 395ms/step - loss: 1.9729e-04 - mean_absolute_error: 0.0113 - val_loss: 9.4902e-05 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.00009\n",
      "Epoch 332/500\n",
      "75/75 [==============================] - 30s 396ms/step - loss: 1.9249e-04 - mean_absolute_error: 0.0113 - val_loss: 9.3248e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.00009\n",
      "Epoch 333/500\n",
      "75/75 [==============================] - 30s 402ms/step - loss: 1.7278e-04 - mean_absolute_error: 0.0108 - val_loss: 9.0679e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.00009\n",
      "Epoch 334/500\n",
      "75/75 [==============================] - 30s 397ms/step - loss: 2.0672e-04 - mean_absolute_error: 0.0115 - val_loss: 1.1067e-04 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.00009\n",
      "Epoch 335/500\n",
      "75/75 [==============================] - 30s 402ms/step - loss: 1.8839e-04 - mean_absolute_error: 0.0110 - val_loss: 9.0290e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.00009\n",
      "Epoch 336/500\n",
      "75/75 [==============================] - 30s 407ms/step - loss: 1.6685e-04 - mean_absolute_error: 0.0106 - val_loss: 9.4950e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.00009\n",
      "Epoch 337/500\n",
      "75/75 [==============================] - 29s 392ms/step - loss: 2.0120e-04 - mean_absolute_error: 0.0115 - val_loss: 1.2051e-04 - val_mean_absolute_error: 0.0083\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.00009\n",
      "Epoch 338/500\n",
      "75/75 [==============================] - 32s 421ms/step - loss: 1.9433e-04 - mean_absolute_error: 0.0113 - val_loss: 1.0419e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.00009\n",
      "Epoch 339/500\n",
      "75/75 [==============================] - 30s 395ms/step - loss: 2.1456e-04 - mean_absolute_error: 0.0115 - val_loss: 1.0607e-04 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.00009\n",
      "Epoch 340/500\n",
      "75/75 [==============================] - 30s 401ms/step - loss: 2.1133e-04 - mean_absolute_error: 0.0119 - val_loss: 8.8146e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.00009\n",
      "Epoch 341/500\n",
      "75/75 [==============================] - 29s 390ms/step - loss: 2.0371e-04 - mean_absolute_error: 0.0114 - val_loss: 8.2064e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00341: val_loss improved from 0.00009 to 0.00008, saving model to results\\2021-04-16_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 342/500\n",
      "75/75 [==============================] - 30s 400ms/step - loss: 1.5869e-04 - mean_absolute_error: 0.0104 - val_loss: 8.9969e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.00008\n",
      "Epoch 343/500\n",
      "75/75 [==============================] - 30s 394ms/step - loss: 1.8079e-04 - mean_absolute_error: 0.0109 - val_loss: 8.8949e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.00008\n",
      "Epoch 344/500\n",
      "75/75 [==============================] - 30s 406ms/step - loss: 1.8439e-04 - mean_absolute_error: 0.0111 - val_loss: 1.1280e-04 - val_mean_absolute_error: 0.0075\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.00008\n",
      "Epoch 345/500\n",
      "75/75 [==============================] - 30s 395ms/step - loss: 2.2156e-04 - mean_absolute_error: 0.0121 - val_loss: 8.1719e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00345: val_loss improved from 0.00008 to 0.00008, saving model to results\\2021-04-16_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 346/500\n",
      "75/75 [==============================] - 30s 400ms/step - loss: 1.7682e-04 - mean_absolute_error: 0.0109 - val_loss: 7.5980e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00346: val_loss improved from 0.00008 to 0.00008, saving model to results\\2021-04-16_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 347/500\n",
      "75/75 [==============================] - 30s 396ms/step - loss: 1.5858e-04 - mean_absolute_error: 0.0104 - val_loss: 7.5124e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00347: val_loss improved from 0.00008 to 0.00008, saving model to results\\2021-04-16_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 348/500\n",
      "75/75 [==============================] - 30s 401ms/step - loss: 1.7421e-04 - mean_absolute_error: 0.0110 - val_loss: 7.7560e-05 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.00008\n",
      "Epoch 349/500\n",
      "75/75 [==============================] - 30s 394ms/step - loss: 1.7089e-04 - mean_absolute_error: 0.0110 - val_loss: 7.6143e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.00008\n",
      "Epoch 350/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 29s 390ms/step - loss: 2.0001e-04 - mean_absolute_error: 0.0115 - val_loss: 9.1753e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.00008\n",
      "Epoch 351/500\n",
      "75/75 [==============================] - 29s 391ms/step - loss: 1.7844e-04 - mean_absolute_error: 0.0109 - val_loss: 9.1079e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.00008\n",
      "Epoch 352/500\n",
      "75/75 [==============================] - 30s 396ms/step - loss: 1.7346e-04 - mean_absolute_error: 0.0109 - val_loss: 1.2083e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.00008\n",
      "Epoch 353/500\n",
      "75/75 [==============================] - 30s 399ms/step - loss: 2.0560e-04 - mean_absolute_error: 0.0118 - val_loss: 1.0481e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.00008\n",
      "Epoch 354/500\n",
      "75/75 [==============================] - 30s 395ms/step - loss: 2.0093e-04 - mean_absolute_error: 0.0112 - val_loss: 1.1638e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.00008\n",
      "Epoch 355/500\n",
      "75/75 [==============================] - 30s 398ms/step - loss: 1.8362e-04 - mean_absolute_error: 0.0111 - val_loss: 7.9666e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.00008\n",
      "Epoch 356/500\n",
      "75/75 [==============================] - 30s 403ms/step - loss: 1.6892e-04 - mean_absolute_error: 0.0107 - val_loss: 8.6566e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.00008\n",
      "Epoch 357/500\n",
      "75/75 [==============================] - 29s 391ms/step - loss: 1.9351e-04 - mean_absolute_error: 0.0115 - val_loss: 7.8147e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.00008\n",
      "Epoch 358/500\n",
      "75/75 [==============================] - 29s 394ms/step - loss: 1.5225e-04 - mean_absolute_error: 0.0104 - val_loss: 1.0724e-04 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.00008\n",
      "Epoch 359/500\n",
      "75/75 [==============================] - 29s 391ms/step - loss: 1.9756e-04 - mean_absolute_error: 0.0114 - val_loss: 8.5810e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.00008\n",
      "Epoch 360/500\n",
      "75/75 [==============================] - 30s 395ms/step - loss: 1.8325e-04 - mean_absolute_error: 0.0111 - val_loss: 7.7701e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.00008\n",
      "Epoch 361/500\n",
      "75/75 [==============================] - 29s 391ms/step - loss: 1.5692e-04 - mean_absolute_error: 0.0107 - val_loss: 1.0328e-04 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.00008\n",
      "Epoch 362/500\n",
      "75/75 [==============================] - 29s 394ms/step - loss: 1.7868e-04 - mean_absolute_error: 0.0110 - val_loss: 7.7006e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.00008\n",
      "Epoch 363/500\n",
      "75/75 [==============================] - 30s 399ms/step - loss: 1.6005e-04 - mean_absolute_error: 0.0104 - val_loss: 6.9030e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00363: val_loss improved from 0.00008 to 0.00007, saving model to results\\2021-04-16_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 364/500\n",
      "75/75 [==============================] - 30s 399ms/step - loss: 1.4057e-04 - mean_absolute_error: 0.0101 - val_loss: 9.7997e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.00007\n",
      "Epoch 365/500\n",
      "75/75 [==============================] - 29s 393ms/step - loss: 1.6067e-04 - mean_absolute_error: 0.0105 - val_loss: 8.6722e-05 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.00007\n",
      "Epoch 366/500\n",
      "75/75 [==============================] - 29s 391ms/step - loss: 1.7973e-04 - mean_absolute_error: 0.0111 - val_loss: 7.7740e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.00007\n",
      "Epoch 367/500\n",
      "75/75 [==============================] - 29s 391ms/step - loss: 1.9016e-04 - mean_absolute_error: 0.0110 - val_loss: 8.9652e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.00007\n",
      "Epoch 368/500\n",
      "75/75 [==============================] - 30s 396ms/step - loss: 1.7655e-04 - mean_absolute_error: 0.0108 - val_loss: 8.1154e-05 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.00007\n",
      "Epoch 369/500\n",
      "75/75 [==============================] - 29s 393ms/step - loss: 1.6940e-04 - mean_absolute_error: 0.0109 - val_loss: 1.0289e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.00007\n",
      "Epoch 370/500\n",
      "75/75 [==============================] - 29s 393ms/step - loss: 1.6963e-04 - mean_absolute_error: 0.0108 - val_loss: 7.4435e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.00007\n",
      "Epoch 371/500\n",
      "75/75 [==============================] - 29s 391ms/step - loss: 1.6875e-04 - mean_absolute_error: 0.0106 - val_loss: 8.7762e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.00007\n",
      "Epoch 372/500\n",
      "75/75 [==============================] - 29s 393ms/step - loss: 1.7449e-04 - mean_absolute_error: 0.0110 - val_loss: 7.2816e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.00007\n",
      "Epoch 373/500\n",
      "75/75 [==============================] - 30s 398ms/step - loss: 1.5819e-04 - mean_absolute_error: 0.0106 - val_loss: 7.3858e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.00007\n",
      "Epoch 374/500\n",
      "75/75 [==============================] - 30s 396ms/step - loss: 1.5258e-04 - mean_absolute_error: 0.0101 - val_loss: 6.6961e-05 - val_mean_absolute_error: 0.0056\n",
      "\n",
      "Epoch 00374: val_loss improved from 0.00007 to 0.00007, saving model to results\\2021-04-16_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 375/500\n",
      "75/75 [==============================] - 32s 428ms/step - loss: 1.5866e-04 - mean_absolute_error: 0.0102 - val_loss: 7.2316e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.00007\n",
      "Epoch 376/500\n",
      "75/75 [==============================] - 30s 397ms/step - loss: 1.7770e-04 - mean_absolute_error: 0.0108 - val_loss: 8.2180e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.00007\n",
      "Epoch 377/500\n",
      "75/75 [==============================] - 30s 397ms/step - loss: 1.5135e-04 - mean_absolute_error: 0.0105 - val_loss: 7.0262e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.00007\n",
      "Epoch 378/500\n",
      "75/75 [==============================] - 30s 395ms/step - loss: 1.8043e-04 - mean_absolute_error: 0.0110 - val_loss: 9.0780e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.00007\n",
      "Epoch 379/500\n",
      "75/75 [==============================] - 30s 395ms/step - loss: 1.8298e-04 - mean_absolute_error: 0.0111 - val_loss: 7.3738e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.00007\n",
      "Epoch 380/500\n",
      "75/75 [==============================] - 30s 399ms/step - loss: 1.6882e-04 - mean_absolute_error: 0.0108 - val_loss: 7.3191e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.00007\n",
      "Epoch 381/500\n",
      "75/75 [==============================] - 29s 392ms/step - loss: 1.7231e-04 - mean_absolute_error: 0.0108 - val_loss: 6.8113e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.00007\n",
      "Epoch 382/500\n",
      "75/75 [==============================] - 31s 414ms/step - loss: 1.6662e-04 - mean_absolute_error: 0.0105 - val_loss: 7.7237e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.00007\n",
      "Epoch 383/500\n",
      "75/75 [==============================] - 30s 396ms/step - loss: 1.6796e-04 - mean_absolute_error: 0.0106 - val_loss: 9.3619e-05 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.00007\n",
      "Epoch 384/500\n",
      "75/75 [==============================] - 30s 399ms/step - loss: 1.6914e-04 - mean_absolute_error: 0.0107 - val_loss: 7.1908e-05 - val_mean_absolute_error: 0.0058\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.00007\n",
      "Epoch 385/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 30s 398ms/step - loss: 1.7074e-04 - mean_absolute_error: 0.0107 - val_loss: 7.4428e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.00007\n",
      "Epoch 386/500\n",
      "75/75 [==============================] - 30s 399ms/step - loss: 1.6239e-04 - mean_absolute_error: 0.0107 - val_loss: 7.2355e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.00007\n",
      "Epoch 387/500\n",
      "75/75 [==============================] - 30s 398ms/step - loss: 1.9748e-04 - mean_absolute_error: 0.0111 - val_loss: 8.9299e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.00007\n",
      "Epoch 388/500\n",
      "75/75 [==============================] - 31s 417ms/step - loss: 1.9319e-04 - mean_absolute_error: 0.0112 - val_loss: 1.0282e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.00007\n",
      "Epoch 389/500\n",
      "75/75 [==============================] - 31s 413ms/step - loss: 1.8406e-04 - mean_absolute_error: 0.0111 - val_loss: 8.1322e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.00007\n",
      "Epoch 390/500\n",
      "75/75 [==============================] - 31s 416ms/step - loss: 1.9536e-04 - mean_absolute_error: 0.0113 - val_loss: 1.0412e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.00007\n",
      "Epoch 391/500\n",
      "75/75 [==============================] - 30s 397ms/step - loss: 1.7510e-04 - mean_absolute_error: 0.0109 - val_loss: 7.2322e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.00007\n",
      "Epoch 392/500\n",
      "75/75 [==============================] - 30s 394ms/step - loss: 1.5170e-04 - mean_absolute_error: 0.0103 - val_loss: 9.5541e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.00007\n",
      "Epoch 393/500\n",
      "75/75 [==============================] - 31s 417ms/step - loss: 1.7560e-04 - mean_absolute_error: 0.0112 - val_loss: 7.5302e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.00007\n",
      "Epoch 394/500\n",
      "75/75 [==============================] - 31s 416ms/step - loss: 1.6728e-04 - mean_absolute_error: 0.0108 - val_loss: 7.9192e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.00007\n",
      "Epoch 395/500\n",
      "75/75 [==============================] - 31s 410ms/step - loss: 1.6821e-04 - mean_absolute_error: 0.0106 - val_loss: 6.6702e-05 - val_mean_absolute_error: 0.0057\n",
      "\n",
      "Epoch 00395: val_loss improved from 0.00007 to 0.00007, saving model to results\\2021-04-16_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 396/500\n",
      "75/75 [==============================] - 30s 401ms/step - loss: 1.5658e-04 - mean_absolute_error: 0.0104 - val_loss: 7.7113e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.00007\n",
      "Epoch 397/500\n",
      "75/75 [==============================] - 32s 431ms/step - loss: 1.5556e-04 - mean_absolute_error: 0.0105 - val_loss: 6.9800e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.00007\n",
      "Epoch 398/500\n",
      "75/75 [==============================] - 35s 467ms/step - loss: 1.7152e-04 - mean_absolute_error: 0.0108 - val_loss: 9.4922e-05 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.00007\n",
      "Epoch 399/500\n",
      "75/75 [==============================] - 32s 433ms/step - loss: 1.5406e-04 - mean_absolute_error: 0.0106 - val_loss: 6.9014e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.00007\n",
      "Epoch 400/500\n",
      "75/75 [==============================] - 32s 427ms/step - loss: 1.5450e-04 - mean_absolute_error: 0.0106 - val_loss: 7.3468e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.00007\n",
      "Epoch 401/500\n",
      "75/75 [==============================] - 32s 424ms/step - loss: 1.7375e-04 - mean_absolute_error: 0.0107 - val_loss: 7.2973e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.00007\n",
      "Epoch 402/500\n",
      "75/75 [==============================] - 33s 444ms/step - loss: 1.6402e-04 - mean_absolute_error: 0.0106 - val_loss: 7.3947e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.00007\n",
      "Epoch 403/500\n",
      "75/75 [==============================] - 34s 449ms/step - loss: 1.6101e-04 - mean_absolute_error: 0.0105 - val_loss: 7.7914e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.00007\n",
      "Epoch 404/500\n",
      "75/75 [==============================] - 32s 421ms/step - loss: 1.6332e-04 - mean_absolute_error: 0.0107 - val_loss: 7.1493e-05 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.00007\n",
      "Epoch 405/500\n",
      "75/75 [==============================] - 31s 413ms/step - loss: 1.6577e-04 - mean_absolute_error: 0.0109 - val_loss: 7.9065e-05 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.00007\n",
      "Epoch 406/500\n",
      "75/75 [==============================] - 30s 397ms/step - loss: 1.5592e-04 - mean_absolute_error: 0.0105 - val_loss: 6.3736e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00406: val_loss improved from 0.00007 to 0.00006, saving model to results\\2021-04-16_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 407/500\n",
      "75/75 [==============================] - 30s 402ms/step - loss: 1.6355e-04 - mean_absolute_error: 0.0105 - val_loss: 8.9748e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.00006\n",
      "Epoch 408/500\n",
      "75/75 [==============================] - 30s 397ms/step - loss: 1.5048e-04 - mean_absolute_error: 0.0102 - val_loss: 1.0104e-04 - val_mean_absolute_error: 0.0081\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.00006\n",
      "Epoch 409/500\n",
      "75/75 [==============================] - 30s 395ms/step - loss: 1.6427e-04 - mean_absolute_error: 0.0108 - val_loss: 7.3553e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.00006\n",
      "Epoch 410/500\n",
      "75/75 [==============================] - 30s 394ms/step - loss: 1.8641e-04 - mean_absolute_error: 0.0110 - val_loss: 6.9574e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.00006\n",
      "Epoch 411/500\n",
      "75/75 [==============================] - 30s 397ms/step - loss: 1.8316e-04 - mean_absolute_error: 0.0111 - val_loss: 7.4917e-05 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.00006\n",
      "Epoch 412/500\n",
      "75/75 [==============================] - 30s 402ms/step - loss: 1.7713e-04 - mean_absolute_error: 0.0108 - val_loss: 7.1732e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.00006\n",
      "Epoch 413/500\n",
      "75/75 [==============================] - 30s 395ms/step - loss: 1.6122e-04 - mean_absolute_error: 0.0107 - val_loss: 7.1785e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.00006\n",
      "Epoch 414/500\n",
      "75/75 [==============================] - 31s 414ms/step - loss: 1.5112e-04 - mean_absolute_error: 0.0104 - val_loss: 9.1296e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.00006\n",
      "Epoch 415/500\n",
      "75/75 [==============================] - 30s 404ms/step - loss: 1.5909e-04 - mean_absolute_error: 0.0107 - val_loss: 7.8079e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.00006\n",
      "Epoch 416/500\n",
      "75/75 [==============================] - 29s 394ms/step - loss: 1.4615e-04 - mean_absolute_error: 0.0104 - val_loss: 8.5451e-05 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.00006\n",
      "Epoch 417/500\n",
      "75/75 [==============================] - 30s 397ms/step - loss: 1.4617e-04 - mean_absolute_error: 0.0102 - val_loss: 6.9124e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.00006\n",
      "Epoch 418/500\n",
      "75/75 [==============================] - 31s 415ms/step - loss: 1.6713e-04 - mean_absolute_error: 0.0108 - val_loss: 6.6607e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.00006\n",
      "Epoch 419/500\n",
      "75/75 [==============================] - 30s 405ms/step - loss: 1.5463e-04 - mean_absolute_error: 0.0103 - val_loss: 7.1661e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.00006\n",
      "Epoch 420/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 30s 396ms/step - loss: 1.4702e-04 - mean_absolute_error: 0.0101 - val_loss: 7.0219e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.00006\n",
      "Epoch 421/500\n",
      "75/75 [==============================] - 29s 392ms/step - loss: 1.7394e-04 - mean_absolute_error: 0.0110 - val_loss: 6.3333e-05 - val_mean_absolute_error: 0.0057\n",
      "\n",
      "Epoch 00421: val_loss improved from 0.00006 to 0.00006, saving model to results\\2021-04-16_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 422/500\n",
      "75/75 [==============================] - 31s 412ms/step - loss: 1.7907e-04 - mean_absolute_error: 0.0108 - val_loss: 6.2408e-05 - val_mean_absolute_error: 0.0057\n",
      "\n",
      "Epoch 00422: val_loss improved from 0.00006 to 0.00006, saving model to results\\2021-04-16_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 423/500\n",
      "75/75 [==============================] - 31s 419ms/step - loss: 1.4682e-04 - mean_absolute_error: 0.0102 - val_loss: 6.7043e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.00006\n",
      "Epoch 424/500\n",
      "75/75 [==============================] - 29s 392ms/step - loss: 1.6953e-04 - mean_absolute_error: 0.0105 - val_loss: 6.8800e-05 - val_mean_absolute_error: 0.0058\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.00006\n",
      "Epoch 425/500\n",
      "75/75 [==============================] - 29s 394ms/step - loss: 1.5571e-04 - mean_absolute_error: 0.0105 - val_loss: 7.7501e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.00006\n",
      "Epoch 426/500\n",
      "75/75 [==============================] - 30s 396ms/step - loss: 1.5531e-04 - mean_absolute_error: 0.0104 - val_loss: 6.6875e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.00006\n",
      "Epoch 427/500\n",
      "75/75 [==============================] - 29s 393ms/step - loss: 1.5705e-04 - mean_absolute_error: 0.0104 - val_loss: 8.7681e-05 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.00006\n",
      "Epoch 428/500\n",
      "75/75 [==============================] - 30s 396ms/step - loss: 1.5016e-04 - mean_absolute_error: 0.0101 - val_loss: 9.0418e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.00006\n",
      "Epoch 429/500\n",
      "75/75 [==============================] - 29s 392ms/step - loss: 1.8553e-04 - mean_absolute_error: 0.0111 - val_loss: 8.2694e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.00006\n",
      "Epoch 430/500\n",
      "75/75 [==============================] - 29s 391ms/step - loss: 1.5551e-04 - mean_absolute_error: 0.0106 - val_loss: 6.9021e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.00006\n",
      "Epoch 431/500\n",
      "75/75 [==============================] - 29s 393ms/step - loss: 1.6659e-04 - mean_absolute_error: 0.0107 - val_loss: 7.8336e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.00006\n",
      "Epoch 432/500\n",
      "75/75 [==============================] - 30s 398ms/step - loss: 1.5768e-04 - mean_absolute_error: 0.0106 - val_loss: 6.6099e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.00006\n",
      "Epoch 433/500\n",
      "75/75 [==============================] - 30s 402ms/step - loss: 1.5971e-04 - mean_absolute_error: 0.0103 - val_loss: 7.0668e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.00006\n",
      "Epoch 434/500\n",
      "75/75 [==============================] - 36s 482ms/step - loss: 1.4809e-04 - mean_absolute_error: 0.0102 - val_loss: 6.3430e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.00006\n",
      "Epoch 435/500\n",
      "75/75 [==============================] - 30s 395ms/step - loss: 1.5863e-04 - mean_absolute_error: 0.0103 - val_loss: 1.0153e-04 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.00006\n",
      "Epoch 436/500\n",
      "75/75 [==============================] - 29s 384ms/step - loss: 1.5496e-04 - mean_absolute_error: 0.0105 - val_loss: 6.3775e-05 - val_mean_absolute_error: 0.0057\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.00006\n",
      "Epoch 437/500\n",
      "75/75 [==============================] - 28s 379ms/step - loss: 1.5226e-04 - mean_absolute_error: 0.0105 - val_loss: 1.0393e-04 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.00006\n",
      "Epoch 438/500\n",
      "75/75 [==============================] - 29s 385ms/step - loss: 1.7075e-04 - mean_absolute_error: 0.0108 - val_loss: 7.5762e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.00006\n",
      "Epoch 439/500\n",
      "75/75 [==============================] - 31s 416ms/step - loss: 1.4944e-04 - mean_absolute_error: 0.0102 - val_loss: 7.8390e-05 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.00006\n",
      "Epoch 440/500\n",
      "75/75 [==============================] - 33s 445ms/step - loss: 1.4296e-04 - mean_absolute_error: 0.0103 - val_loss: 7.6704e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.00006\n",
      "Epoch 441/500\n",
      "75/75 [==============================] - 32s 431ms/step - loss: 1.5608e-04 - mean_absolute_error: 0.0105 - val_loss: 6.5517e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.00006\n",
      "Epoch 442/500\n",
      "75/75 [==============================] - 30s 404ms/step - loss: 1.5813e-04 - mean_absolute_error: 0.0107 - val_loss: 6.3088e-05 - val_mean_absolute_error: 0.0058\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.00006\n",
      "Epoch 443/500\n",
      "75/75 [==============================] - 30s 403ms/step - loss: 1.4318e-04 - mean_absolute_error: 0.0102 - val_loss: 6.1091e-05 - val_mean_absolute_error: 0.0057\n",
      "\n",
      "Epoch 00443: val_loss improved from 0.00006 to 0.00006, saving model to results\\2021-04-16_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 444/500\n",
      "75/75 [==============================] - 31s 413ms/step - loss: 1.5328e-04 - mean_absolute_error: 0.0103 - val_loss: 6.7494e-05 - val_mean_absolute_error: 0.0058\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.00006\n",
      "Epoch 445/500\n",
      "75/75 [==============================] - 30s 403ms/step - loss: 1.6916e-04 - mean_absolute_error: 0.0107 - val_loss: 9.8232e-05 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.00006\n",
      "Epoch 446/500\n",
      "75/75 [==============================] - 31s 409ms/step - loss: 1.7708e-04 - mean_absolute_error: 0.0110 - val_loss: 7.8054e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.00006\n",
      "Epoch 447/500\n",
      "75/75 [==============================] - 31s 408ms/step - loss: 1.6267e-04 - mean_absolute_error: 0.0106 - val_loss: 7.1973e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.00006\n",
      "Epoch 448/500\n",
      "75/75 [==============================] - 31s 417ms/step - loss: 1.7256e-04 - mean_absolute_error: 0.0107 - val_loss: 6.5681e-05 - val_mean_absolute_error: 0.0058\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.00006\n",
      "Epoch 449/500\n",
      "75/75 [==============================] - 34s 454ms/step - loss: 1.4874e-04 - mean_absolute_error: 0.0102 - val_loss: 7.1710e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.00006\n",
      "Epoch 450/500\n",
      "75/75 [==============================] - 33s 437ms/step - loss: 1.3200e-04 - mean_absolute_error: 0.0100 - val_loss: 7.6874e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.00006\n",
      "Epoch 451/500\n",
      "75/75 [==============================] - 31s 419ms/step - loss: 1.5426e-04 - mean_absolute_error: 0.0104 - val_loss: 7.7008e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.00006\n",
      "Epoch 452/500\n",
      "75/75 [==============================] - 31s 410ms/step - loss: 1.5173e-04 - mean_absolute_error: 0.0104 - val_loss: 8.1909e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.00006\n",
      "Epoch 453/500\n",
      "75/75 [==============================] - 30s 400ms/step - loss: 1.5255e-04 - mean_absolute_error: 0.0102 - val_loss: 9.4785e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.00006\n",
      "Epoch 454/500\n",
      "75/75 [==============================] - 30s 397ms/step - loss: 1.7322e-04 - mean_absolute_error: 0.0108 - val_loss: 7.4422e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.00006\n",
      "Epoch 455/500\n",
      "75/75 [==============================] - 30s 399ms/step - loss: 1.7692e-04 - mean_absolute_error: 0.0107 - val_loss: 7.4576e-05 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.00006\n",
      "Epoch 456/500\n",
      "75/75 [==============================] - 29s 394ms/step - loss: 1.5891e-04 - mean_absolute_error: 0.0107 - val_loss: 6.7484e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.00006\n",
      "Epoch 457/500\n",
      "75/75 [==============================] - 34s 449ms/step - loss: 1.5626e-04 - mean_absolute_error: 0.0104 - val_loss: 6.4390e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.00006\n",
      "Epoch 458/500\n",
      "75/75 [==============================] - 31s 419ms/step - loss: 1.5725e-04 - mean_absolute_error: 0.0106 - val_loss: 8.5161e-05 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.00006\n",
      "Epoch 459/500\n",
      "75/75 [==============================] - 31s 418ms/step - loss: 1.3975e-04 - mean_absolute_error: 0.0102 - val_loss: 6.4955e-05 - val_mean_absolute_error: 0.0056\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.00006\n",
      "Epoch 460/500\n",
      "75/75 [==============================] - 30s 402ms/step - loss: 1.4541e-04 - mean_absolute_error: 0.0102 - val_loss: 7.2983e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.00006\n",
      "Epoch 461/500\n",
      "75/75 [==============================] - 30s 395ms/step - loss: 1.4418e-04 - mean_absolute_error: 0.0102 - val_loss: 7.3309e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.00006\n",
      "Epoch 462/500\n",
      "75/75 [==============================] - 30s 396ms/step - loss: 1.7985e-04 - mean_absolute_error: 0.0110 - val_loss: 9.6523e-05 - val_mean_absolute_error: 0.0075\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.00006\n",
      "Epoch 463/500\n",
      "75/75 [==============================] - 31s 418ms/step - loss: 1.5997e-04 - mean_absolute_error: 0.0107 - val_loss: 6.8932e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.00006\n",
      "Epoch 464/500\n",
      "75/75 [==============================] - 30s 403ms/step - loss: 1.4821e-04 - mean_absolute_error: 0.0102 - val_loss: 6.8429e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.00006\n",
      "Epoch 465/500\n",
      "75/75 [==============================] - 30s 407ms/step - loss: 1.5238e-04 - mean_absolute_error: 0.0103 - val_loss: 8.5520e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.00006\n",
      "Epoch 466/500\n",
      "75/75 [==============================] - 30s 405ms/step - loss: 1.7076e-04 - mean_absolute_error: 0.0108 - val_loss: 6.1867e-05 - val_mean_absolute_error: 0.0057\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.00006\n",
      "Epoch 467/500\n",
      "75/75 [==============================] - 30s 399ms/step - loss: 1.3498e-04 - mean_absolute_error: 0.0100 - val_loss: 7.1544e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.00006\n",
      "Epoch 468/500\n",
      "75/75 [==============================] - 29s 393ms/step - loss: 1.4653e-04 - mean_absolute_error: 0.0103 - val_loss: 6.7543e-05 - val_mean_absolute_error: 0.0057\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.00006\n",
      "Epoch 469/500\n",
      "75/75 [==============================] - 29s 391ms/step - loss: 1.5930e-04 - mean_absolute_error: 0.0102 - val_loss: 6.3980e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.00006\n",
      "Epoch 470/500\n",
      "75/75 [==============================] - 30s 404ms/step - loss: 1.6790e-04 - mean_absolute_error: 0.0108 - val_loss: 6.7621e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.00006\n",
      "Epoch 471/500\n",
      "75/75 [==============================] - 31s 411ms/step - loss: 1.5640e-04 - mean_absolute_error: 0.0105 - val_loss: 6.8646e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.00006\n",
      "Epoch 472/500\n",
      "75/75 [==============================] - 30s 402ms/step - loss: 1.6663e-04 - mean_absolute_error: 0.0106 - val_loss: 6.3653e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.00006\n",
      "Epoch 473/500\n",
      "75/75 [==============================] - 30s 407ms/step - loss: 1.4349e-04 - mean_absolute_error: 0.0102 - val_loss: 7.1286e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.00006\n",
      "Epoch 474/500\n",
      "75/75 [==============================] - 30s 404ms/step - loss: 1.4935e-04 - mean_absolute_error: 0.0103 - val_loss: 8.4553e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.00006\n",
      "Epoch 475/500\n",
      "75/75 [==============================] - 31s 414ms/step - loss: 1.5292e-04 - mean_absolute_error: 0.0106 - val_loss: 6.6177e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.00006\n",
      "Epoch 476/500\n",
      "75/75 [==============================] - 30s 398ms/step - loss: 1.6336e-04 - mean_absolute_error: 0.0104 - val_loss: 9.9887e-05 - val_mean_absolute_error: 0.0080\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.00006\n",
      "Epoch 477/500\n",
      "75/75 [==============================] - 31s 412ms/step - loss: 1.6779e-04 - mean_absolute_error: 0.0108 - val_loss: 6.7680e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.00006\n",
      "Epoch 478/500\n",
      "75/75 [==============================] - 31s 409ms/step - loss: 1.4991e-04 - mean_absolute_error: 0.0102 - val_loss: 7.3104e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.00006\n",
      "Epoch 479/500\n",
      "75/75 [==============================] - 30s 403ms/step - loss: 1.3506e-04 - mean_absolute_error: 0.0098 - val_loss: 6.9008e-05 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.00006\n",
      "Epoch 480/500\n",
      "75/75 [==============================] - 29s 393ms/step - loss: 1.5286e-04 - mean_absolute_error: 0.0103 - val_loss: 6.9579e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.00006\n",
      "Epoch 481/500\n",
      "75/75 [==============================] - 35s 469ms/step - loss: 1.3651e-04 - mean_absolute_error: 0.0099 - val_loss: 6.0298e-05 - val_mean_absolute_error: 0.0055\n",
      "\n",
      "Epoch 00481: val_loss improved from 0.00006 to 0.00006, saving model to results\\2021-04-16_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 482/500\n",
      "75/75 [==============================] - 45s 607ms/step - loss: 1.7466e-04 - mean_absolute_error: 0.0108 - val_loss: 7.0649e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.00006\n",
      "Epoch 483/500\n",
      "75/75 [==============================] - 36s 484ms/step - loss: 1.3737e-04 - mean_absolute_error: 0.0101 - val_loss: 7.3245e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.00006\n",
      "Epoch 484/500\n",
      "75/75 [==============================] - 35s 466ms/step - loss: 1.6938e-04 - mean_absolute_error: 0.0104 - val_loss: 6.7085e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.00006\n",
      "Epoch 485/500\n",
      "75/75 [==============================] - 37s 495ms/step - loss: 1.5003e-04 - mean_absolute_error: 0.0102 - val_loss: 7.3416e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.00006\n",
      "Epoch 486/500\n",
      "75/75 [==============================] - 37s 492ms/step - loss: 1.5902e-04 - mean_absolute_error: 0.0103 - val_loss: 6.7655e-05 - val_mean_absolute_error: 0.0057\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.00006\n",
      "Epoch 487/500\n",
      "75/75 [==============================] - 34s 459ms/step - loss: 1.7260e-04 - mean_absolute_error: 0.0108 - val_loss: 6.5797e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.00006\n",
      "Epoch 488/500\n",
      "75/75 [==============================] - 38s 507ms/step - loss: 1.7164e-04 - mean_absolute_error: 0.0107 - val_loss: 6.8326e-05 - val_mean_absolute_error: 0.0058\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.00006\n",
      "Epoch 489/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 36s 479ms/step - loss: 1.6316e-04 - mean_absolute_error: 0.0105 - val_loss: 6.6931e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.00006\n",
      "Epoch 490/500\n",
      "75/75 [==============================] - 35s 468ms/step - loss: 1.3990e-04 - mean_absolute_error: 0.0102 - val_loss: 6.9670e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.00006\n",
      "Epoch 491/500\n",
      "75/75 [==============================] - 35s 465ms/step - loss: 1.4190e-04 - mean_absolute_error: 0.0099 - val_loss: 6.3461e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.00006\n",
      "Epoch 492/500\n",
      "75/75 [==============================] - 40s 535ms/step - loss: 1.5998e-04 - mean_absolute_error: 0.0104 - val_loss: 6.2136e-05 - val_mean_absolute_error: 0.0056\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.00006\n",
      "Epoch 493/500\n",
      "75/75 [==============================] - 38s 510ms/step - loss: 1.4508e-04 - mean_absolute_error: 0.0101 - val_loss: 7.6924e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.00006\n",
      "Epoch 494/500\n",
      "75/75 [==============================] - 35s 472ms/step - loss: 1.5904e-04 - mean_absolute_error: 0.0104 - val_loss: 7.7146e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.00006\n",
      "Epoch 495/500\n",
      "75/75 [==============================] - 37s 490ms/step - loss: 1.4943e-04 - mean_absolute_error: 0.0101 - val_loss: 7.7029e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.00006\n",
      "Epoch 496/500\n",
      "75/75 [==============================] - 36s 486ms/step - loss: 1.4607e-04 - mean_absolute_error: 0.0104 - val_loss: 6.2046e-05 - val_mean_absolute_error: 0.0056\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.00006\n",
      "Epoch 497/500\n",
      "75/75 [==============================] - 37s 498ms/step - loss: 1.3120e-04 - mean_absolute_error: 0.0098 - val_loss: 6.1273e-05 - val_mean_absolute_error: 0.0056\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.00006\n",
      "Epoch 498/500\n",
      "75/75 [==============================] - 30s 400ms/step - loss: 1.5498e-04 - mean_absolute_error: 0.0102 - val_loss: 6.8499e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.00006\n",
      "Epoch 499/500\n",
      "75/75 [==============================] - 29s 392ms/step - loss: 1.6066e-04 - mean_absolute_error: 0.0107 - val_loss: 6.2314e-05 - val_mean_absolute_error: 0.0056\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.00006\n",
      "Epoch 500/500\n",
      "75/75 [==============================] - 29s 393ms/step - loss: 1.5967e-04 - mean_absolute_error: 0.0104 - val_loss: 6.1584e-05 - val_mean_absolute_error: 0.0058\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.00006\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE, \n",
    "                shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, \n",
    "                feature_columns=FEATURE_COLUMNS)\n",
    "\n",
    "# save the dataframe\n",
    "data[\"df\"].to_csv(ticker_data_filename)\n",
    "\n",
    "# construct the model\n",
    "model = create_model(N_STEPS, len(FEATURE_COLUMNS), loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
    "\n",
    "# some tensorflow callbacks\n",
    "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "\n",
    "# train the model and save the weights whenever we see \n",
    "# a new optimal model using ModelCheckpoint\n",
    "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
    "                    callbacks=[checkpointer, tensorboard],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now run the tensorboard command\n",
    "\n",
    "\"\"\" Note: This should be ran in the command line terminal. \n",
    "          This will start a local HTTP server at localhost:6006, \n",
    "          after going to the browser you see a graph of epoch loss over time\"\"\"\n",
    "\n",
    "# tensorboard --logdir=\"logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the Model\n",
    "# The function below takes a pandas dataframe and plots the true and predicted prices in the same plot using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graph(test_df):\n",
    "    \"\"\"\n",
    "    This function plots true close price along with predicted close price\n",
    "    with blue and red colors respectively\n",
    "    \"\"\"\n",
    "    plt.plot(test_df[f'true_adjclose_{LOOKUP_STEP}'], c='b')\n",
    "    plt.plot(test_df[f'adjclose_{LOOKUP_STEP}'], c='r')\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" The below function takes the model and the data that were returned by\n",
    "    create_model() and load_data() functions respectively,\n",
    "    and constructs a dataframe in which it includes the predicted adjclose along with true future adjclose,\n",
    "    as well as calculating buy and sell profit \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_df(model, data):\n",
    "    \"\"\"\n",
    "    This function takes the `model` and `data` dict to \n",
    "    construct a final dataframe that includes the features along \n",
    "    with true and predicted prices of the testing dataset\n",
    "    \"\"\"\n",
    "    # if predicted future price is higher than the current, \n",
    "    # then calculate the true future price minus the current price, to get the buy profit\n",
    "    \n",
    "    buy_profit  = lambda current, true_future, pred_future: true_future - current if pred_future > current else 0\n",
    "    \n",
    "    # if the predicted future price is lower than the current price,\n",
    "    # then subtract the true future price from the current price\n",
    "    sell_profit = lambda current, true_future, pred_future: current - true_future if pred_future < current else 0\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_test = data[\"y_test\"]\n",
    "    \n",
    "    # perform prediction and get prices\n",
    "    y_pred = model.predict(X_test)\n",
    "    if SCALE:\n",
    "        y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "        y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
    "    test_df = data[\"test_df\"]\n",
    "    \n",
    "    # add predicted future prices to the dataframe\n",
    "    test_df[f\"adjclose_{LOOKUP_STEP}\"] = y_pred\n",
    "    \n",
    "    # add true future prices to the dataframe\n",
    "    test_df[f\"true_adjclose_{LOOKUP_STEP}\"] = y_test\n",
    "    \n",
    "    # sort the dataframe by date\n",
    "    test_df.sort_index(inplace=True)\n",
    "    final_df = test_df\n",
    "    \n",
    "    # add the buy profit column\n",
    "    final_df[\"buy_profit\"] = list(map(buy_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    # add the sell profit column\n",
    "    \n",
    "    final_df[\"sell_profit\"] = list(map(sell_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next function is used to predict the next future price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    # retrieve the last sequence from data\n",
    "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
    "    # expand dimension\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    # get the prediction (scaled from 0 to 1)\n",
    "    prediction = model.predict(last_sequence)\n",
    "    # get the price (by inverting the scaling)\n",
    "    if SCALE:\n",
    "        predicted_price = data[\"column_scaler\"][\"adjclose\"].inverse_transform(prediction)[0][0]\n",
    "    else:\n",
    "        predicted_price = prediction[0][0]\n",
    "    return predicted_price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load optimal model weights from results folder\n",
    "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating loss and mean absolute error using model.evaluate() method:\n",
    "# evaluate the model\n",
    "loss, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "# calculate the mean absolute error (inverse scaling)\n",
    "if SCALE:\n",
    "    mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n",
    "else:\n",
    "    mean_absolute_error = mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the final dataframe for the testing set\n",
    "final_df = get_final_df(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the future price\n",
    "future_price = predict(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will calculate the accuracy by counting the number of positive profits\n",
    "accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n",
    "\n",
    "# calculating total buy & sell profit\n",
    "total_buy_profit  = final_df[\"buy_profit\"].sum()\n",
    "total_sell_profit = final_df[\"sell_profit\"].sum()\n",
    "\n",
    "# total profit by adding sell & buy together\n",
    "total_profit = total_buy_profit + total_sell_profit\n",
    "\n",
    "# dividing total profit by number of testing samples (number of trades)\n",
    "profit_per_trade = total_profit / len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future price after 15 days is 3187.62$\n",
      "huber_loss loss: 6.0298156313365325e-05\n",
      "Mean Absolute Error: 20.967476573535535\n",
      "Accuracy score: 0.5343959731543624\n",
      "Total buy profit: 7118.173593593761\n",
      "Total sell profit: 1715.857815593481\n",
      "Total profit: 8834.031409187242\n",
      "Profit per trade: 7.411100175492653\n"
     ]
    }
   ],
   "source": [
    "# printing metrics\n",
    "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")\n",
    "print(f\"{LOSS} loss:\", loss)\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error)\n",
    "print(\"Accuracy score:\", accuracy_score)\n",
    "print(\"Total buy profit:\", total_buy_profit)\n",
    "print(\"Total sell profit:\", total_sell_profit)\n",
    "print(\"Total profit:\", total_profit)\n",
    "print(\"Profit per trade:\", profit_per_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graph(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
