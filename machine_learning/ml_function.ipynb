{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(tick=\"AMZN\", days=7):\n",
    "\n",
    "    # set seed\n",
    "    np.random.seed(314)\n",
    "    tf.random.set_seed(314)\n",
    "    random.seed(314)\n",
    "    \n",
    "    def shuffle_in_unison(a, b):\n",
    "        # shuffle two arrays in the same way\n",
    "        state = np.random.get_state()\n",
    "        np.random.shuffle(a)\n",
    "        np.random.set_state(state)\n",
    "        np.random.shuffle(b)\n",
    "        \n",
    "    def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True,\n",
    "                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
    "        \"\"\"\n",
    "        Loads data from Yahoo Finance source, as well as scaling, shuffling, normalizing and splitting.\n",
    "        Params:\n",
    "            ticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc.\n",
    "            n_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\n",
    "            scale (bool): whether to scale prices from 0 to 1, default is True\n",
    "            shuffle (bool): whether to shuffle the dataset (both training & testing), default is True\n",
    "            lookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\n",
    "            split_by_date (bool): whether we split the dataset into training/testing by date, setting it \n",
    "                to False will split datasets in a random way\n",
    "            test_size (float): ratio for test data, default is 0.2 (20% testing data)\n",
    "            feature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n",
    "        \"\"\"\n",
    "        # Set ticker equal to 'tick' value\n",
    "        ticker = tick\n",
    "        \n",
    "        # see if ticker is already a loaded stock from yahoo finance\n",
    "        if isinstance(ticker, str):\n",
    "            # load it from yahoo_fin library\n",
    "            df = si.get_data(ticker)\n",
    "        elif isinstance(ticker, pd.DataFrame):\n",
    "            # already loaded, use it directly\n",
    "            df = ticker\n",
    "        else:\n",
    "            raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
    "            \n",
    "        # this will contain all the elements we want to return from this function\n",
    "        result = {}\n",
    "        \n",
    "        # we will also return the original dataframe itself\n",
    "        result['df'] = df.copy()\n",
    "        \n",
    "        # make sure that the passed feature_columns exist in the dataframe\n",
    "        for col in feature_columns:\n",
    "            assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "        # add date as a column\n",
    "        if \"date\" not in df.columns:\n",
    "            df[\"date\"] = df.index\n",
    "        if scale:\n",
    "            column_scaler = {}\n",
    "            # scale the data (prices) from 0 to 1\n",
    "            for column in feature_columns:\n",
    "                scaler = preprocessing.MinMaxScaler()\n",
    "                df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "                column_scaler[column] = scaler\n",
    "            # add the MinMaxScaler instances to the result returned\n",
    "            result[\"column_scaler\"] = column_scaler\n",
    "            \n",
    "        # add the target column (label) by shifting by `lookup_step`\n",
    "        df['future'] = df['adjclose'].shift(-lookup_step)\n",
    "        \n",
    "        # last `lookup_step` columns contains NaN in future column\n",
    "        # get them before droping NaNs\n",
    "        last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "        \n",
    "        # drop NaNs\n",
    "        df.dropna(inplace=True)\n",
    "        sequence_data = []\n",
    "        sequences = deque(maxlen=n_steps)\n",
    "        for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
    "            sequences.append(entry)\n",
    "            if len(sequences) == n_steps:\n",
    "                sequence_data.append([np.array(sequences), target])\n",
    "                \n",
    "        # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
    "        # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n",
    "        # this last_sequence will be used to predict future stock prices that are not available in the dataset\n",
    "        last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
    "        last_sequence = np.array(last_sequence).astype(np.float32)\n",
    "        \n",
    "        # add to result\n",
    "        result['last_sequence'] = last_sequence\n",
    "        \n",
    "        # construct the X's and y's\n",
    "        X, y = [], []\n",
    "        for seq, target in sequence_data:\n",
    "            X.append(seq)\n",
    "            y.append(target)\n",
    "            \n",
    "        # convert to numpy arrays\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        if split_by_date:\n",
    "            # split the dataset into training & testing sets by date (not randomly splitting)\n",
    "            train_samples = int((1 - test_size) * len(X))\n",
    "            result[\"X_train\"] = X[:train_samples]\n",
    "            result[\"y_train\"] = y[:train_samples]\n",
    "            result[\"X_test\"]  = X[train_samples:]\n",
    "            result[\"y_test\"]  = y[train_samples:]\n",
    "            if shuffle:\n",
    "                # shuffle the datasets for training (if shuffle parameter is set)\n",
    "                shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
    "                shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
    "        else:    \n",
    "            # split the dataset randomly\n",
    "            result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n",
    "                                                                                    test_size=test_size, shuffle=shuffle)\n",
    "        \n",
    "        # get the list of test set dates\n",
    "        dates = result[\"X_test\"][:, -1, -1]\n",
    "        \n",
    "        # retrieve test features from the original dataframe\n",
    "        result[\"test_df\"] = result[\"df\"].loc[dates]\n",
    "        \n",
    "        # remove duplicated dates in the testing dataframe\n",
    "        result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n",
    "        \n",
    "        # remove dates from the training/testing sets & convert to float32\n",
    "        result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "        result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "        return result\n",
    "    \n",
    "    def create_model(sequence_length, n_features, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
    "        model = Sequential()\n",
    "        for i in range(n_layers):\n",
    "            if i == 0:\n",
    "                # first layer\n",
    "                if bidirectional:\n",
    "                    model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n",
    "                else:\n",
    "                    model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n",
    "            elif i == n_layers - 1:\n",
    "                # last layer\n",
    "                if bidirectional:\n",
    "                    model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "                else:\n",
    "                    model.add(cell(units, return_sequences=False))\n",
    "            else:\n",
    "                # hidden layers\n",
    "                if bidirectional:\n",
    "                    model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "                else:\n",
    "                    model.add(cell(units, return_sequences=True))\n",
    "                    \n",
    "            # add dropout after each layer\n",
    "            model.add(Dropout(dropout))\n",
    "        model.add(Dense(1, activation=\"linear\"))\n",
    "        model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "        return model\n",
    "    \n",
    "    # Window size or the sequence length\n",
    "    N_STEPS = 50\n",
    "\n",
    "    # Lookup step, 1 is the next day\n",
    "    days = days\n",
    "    LOOKUP_STEP = int(days)\n",
    "\n",
    "    # whether to scale feature columns & output price as well\n",
    "    SCALE = True\n",
    "    scale_str = f\"sc-{int(SCALE)}\"\n",
    "\n",
    "    # whether to shuffle the dataset\n",
    "    SHUFFLE = True\n",
    "    shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
    "\n",
    "    # whether to split the training/testing set by date\n",
    "    SPLIT_BY_DATE = False\n",
    "    split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
    "\n",
    "    # test ratio size, 0.2 is 20%\n",
    "    TEST_SIZE = 0.2\n",
    "\n",
    "    # features to use\n",
    "    FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
    "\n",
    "    # date now\n",
    "    date_now = time.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    ### model parameters\n",
    "    N_LAYERS = 2\n",
    "\n",
    "    # LSTM cell\n",
    "    CELL = LSTM\n",
    "\n",
    "    # 256 LSTM neurons\n",
    "    UNITS = 256\n",
    "\n",
    "    # 40% dropout\n",
    "    DROPOUT = 0.4\n",
    "\n",
    "    # whether to use bidirectional RNNs\n",
    "    BIDIRECTIONAL = False\n",
    "\n",
    "    ### training parameters\n",
    "    # mean absolute error loss\n",
    "    # LOSS = \"mae\"\n",
    "    # huber loss\n",
    "    LOSS = \"huber_loss\"\n",
    "    OPTIMIZER = \"adam\"\n",
    "    BATCH_SIZE = 64\n",
    "    EPOCHS = 5\n",
    "\n",
    "    # Save stock market data to date-specific csv\n",
    "    ticker = tick\n",
    "    ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "\n",
    "    # model name to save, making it as unique as possible based on parameters\n",
    "    model_name = f\"{date_now}_{ticker}\"\n",
    "    \n",
    "    if BIDIRECTIONAL:\n",
    "        model_name += \"-b\"\n",
    "    \n",
    "    # create these folders if they does not exist\n",
    "    if not os.path.isdir(\"results\"):\n",
    "        os.mkdir(\"results\")\n",
    "    if not os.path.isdir(\"logs\"):\n",
    "        os.mkdir(\"logs\")\n",
    "    if not os.path.isdir(\"data\"):\n",
    "        os.mkdir(\"data\")\n",
    "        \n",
    "    # Now, make function calls to implement the model\n",
    "    # load the data\n",
    "    data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE, \n",
    "                    shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, \n",
    "                    feature_columns=FEATURE_COLUMNS)\n",
    "\n",
    "    # save the dataframe\n",
    "    data[\"df\"].to_csv(ticker_data_filename)\n",
    "\n",
    "    # construct the model\n",
    "    model = create_model(N_STEPS, len(FEATURE_COLUMNS), loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                        dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
    "\n",
    "    # some tensorflow callbacks\n",
    "    checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "    tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "\n",
    "    # train the model and save the weights whenever we see \n",
    "    # a new optimal model using ModelCheckpoint\n",
    "    history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        epochs=EPOCHS,\n",
    "                        validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
    "                        callbacks=[checkpointer, tensorboard],\n",
    "                        verbose=1)\n",
    "    # Now run the tensorboard command\n",
    "\n",
    "    \"\"\" Note: This should be ran in the command line terminal. \n",
    "              This will start a local HTTP server at localhost:6006, \n",
    "              after going to the browser you see a graph of epoch loss over time\"\"\"\n",
    "\n",
    "    # tensorboard --logdir=\"logs\"\n",
    "    \n",
    "    # Testing the Model\n",
    "    # The function below takes a pandas dataframe and plots the true and predicted prices in the same plot using matplotlib\n",
    "    def plot_graph(test_df):\n",
    "        \"\"\"\n",
    "        This function plots true close price along with predicted close price\n",
    "        with blue and red colors respectively\n",
    "        \"\"\"\n",
    "        plt.plot(test_df[f'true_adjclose_{LOOKUP_STEP}'], c='b')\n",
    "        plt.plot(test_df[f'adjclose_{LOOKUP_STEP}'], c='r')\n",
    "        plt.xlabel(\"Days\")\n",
    "        plt.ylabel(\"Price\")\n",
    "        plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
    "        plt.show()\n",
    "        \n",
    "    \"\"\" The below function takes the model and the data that were returned by\n",
    "        create_model() and load_data() functions respectively,\n",
    "        and constructs a dataframe in which it includes the predicted adjclose along with true future adjclose,\n",
    "        as well as calculating buy and sell profit \"\"\"\n",
    "    \n",
    "    def get_final_df(model, data):\n",
    "        \"\"\"\n",
    "        This function takes the `model` and `data` dict to \n",
    "        construct a final dataframe that includes the features along \n",
    "        with true and predicted prices of the testing dataset\n",
    "        \"\"\"\n",
    "        # if predicted future price is higher than the current, \n",
    "        # then calculate the true future price minus the current price, to get the buy profit\n",
    "\n",
    "        buy_profit  = lambda current, true_future, pred_future: true_future - current if pred_future > current else 0\n",
    "\n",
    "        # if the predicted future price is lower than the current price,\n",
    "        # then subtract the true future price from the current price\n",
    "        sell_profit = lambda current, true_future, pred_future: current - true_future if pred_future < current else 0\n",
    "        X_test = data[\"X_test\"]\n",
    "        y_test = data[\"y_test\"]\n",
    "\n",
    "        # perform prediction and get prices\n",
    "        y_pred = model.predict(X_test)\n",
    "        if SCALE:\n",
    "            y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "            y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
    "        test_df = data[\"test_df\"]\n",
    "\n",
    "        # add predicted future prices to the dataframe\n",
    "        test_df[f\"adjclose_{LOOKUP_STEP}\"] = y_pred\n",
    "\n",
    "        # add true future prices to the dataframe\n",
    "        test_df[f\"true_adjclose_{LOOKUP_STEP}\"] = y_test\n",
    "\n",
    "        # sort the dataframe by date\n",
    "        test_df.sort_index(inplace=True)\n",
    "        final_df = test_df\n",
    "\n",
    "        # add the buy profit column\n",
    "        final_df[\"buy_profit\"] = list(map(buy_profit, \n",
    "                                        final_df[\"adjclose\"], \n",
    "                                        final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                        final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                        # since we don't have profit for last sequence, add 0's\n",
    "                                        )\n",
    "        # add the sell profit column\n",
    "\n",
    "        final_df[\"sell_profit\"] = list(map(sell_profit, \n",
    "                                        final_df[\"adjclose\"], \n",
    "                                        final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                        final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                        # since we don't have profit for last sequence, add 0's\n",
    "                                        )\n",
    "        return final_df\n",
    "    \n",
    "    # The next function is used to predict the next future price\n",
    "    def predict(model, data):\n",
    "        # retrieve the last sequence from data\n",
    "        last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
    "        # expand dimension\n",
    "        last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "        # get the prediction (scaled from 0 to 1)\n",
    "        prediction = model.predict(last_sequence)\n",
    "        # get the price (by inverting the scaling)\n",
    "        if SCALE:\n",
    "            predicted_price = data[\"column_scaler\"][\"adjclose\"].inverse_transform(prediction)[0][0]\n",
    "        else:\n",
    "            predicted_price = prediction[0][0]\n",
    "        return predicted_price\n",
    "    \n",
    "    # load optimal model weights from results folder\n",
    "    model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
    "    model.load_weights(model_path)\n",
    "    \n",
    "    # Calculating loss and mean absolute error using model.evaluate() method:\n",
    "    # evaluate the model\n",
    "    loss, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "    # calculate the mean absolute error (inverse scaling)\n",
    "    if SCALE:\n",
    "        mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n",
    "    else:\n",
    "        mean_absolute_error = mae\n",
    "        \n",
    "    # get the final dataframe for the testing set\n",
    "    final_df = get_final_df(model, data)\n",
    "    \n",
    "    # predict the future price\n",
    "    future_price = predict(model, data)\n",
    "    \n",
    "    # Now we will calculate the accuracy by counting the number of positive profits\n",
    "    accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n",
    "\n",
    "    # calculating total buy & sell profit\n",
    "    total_buy_profit  = final_df[\"buy_profit\"].sum()\n",
    "    total_sell_profit = final_df[\"sell_profit\"].sum()\n",
    "\n",
    "    # total profit by adding sell & buy together\n",
    "    total_profit = total_buy_profit + total_sell_profit\n",
    "\n",
    "    # dividing total profit by number of testing samples (number of trades)\n",
    "    profit_per_trade = total_profit / len(final_df)\n",
    "    \n",
    "    # printing metrics\n",
    "    print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")\n",
    "    print(f\"{LOSS} loss:\", loss)\n",
    "    print(\"Mean Absolute Error:\", mean_absolute_error)\n",
    "    print(\"Accuracy score:\", accuracy_score)\n",
    "    print(\"Total buy profit:\", total_buy_profit)\n",
    "    print(\"Total sell profit:\", total_sell_profit)\n",
    "    print(\"Total profit:\", total_profit)\n",
    "    print(\"Profit per trade:\", profit_per_trade)\n",
    "    \n",
    "    # Plot graph of predicted vs future price\n",
    "    plot_graph(final_df)\n",
    "    \n",
    "    return final_df, future_price, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "75/75 [==============================] - 28s 343ms/step - loss: 0.0021 - mean_absolute_error: 0.0297 - val_loss: 1.1303e-04 - val_mean_absolute_error: 0.0079\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00011, saving model to results\\2021-04-17_AMZN.h5\n",
      "Epoch 2/5\n",
      "75/75 [==============================] - 24s 319ms/step - loss: 4.3080e-04 - mean_absolute_error: 0.0140 - val_loss: 9.4058e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00011 to 0.00009, saving model to results\\2021-04-17_AMZN.h5\n",
      "Epoch 3/5\n",
      "75/75 [==============================] - 24s 326ms/step - loss: 4.3604e-04 - mean_absolute_error: 0.0144 - val_loss: 1.2553e-04 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00009\n",
      "Epoch 4/5\n",
      "75/75 [==============================] - 28s 374ms/step - loss: 3.3479e-04 - mean_absolute_error: 0.0123 - val_loss: 1.3140e-04 - val_mean_absolute_error: 0.0100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00009\n",
      "Epoch 5/5\n",
      "75/75 [==============================] - 32s 423ms/step - loss: 3.3174e-04 - mean_absolute_error: 0.0124 - val_loss: 2.7106e-04 - val_mean_absolute_error: 0.0146\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00009\n",
      "Future price after 7 days is 3242.10$\n",
      "huber_loss loss: 9.405839955434203e-05\n",
      "Mean Absolute Error: 23.972649732141466\n",
      "Accuracy score: 0.46353730092204526\n",
      "Total buy profit: -3011.9400528669357\n",
      "Total sell profit: 2382.6119735240936\n",
      "Total profit: -629.3280793428421\n",
      "Profit per trade: -0.5275172500778224\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(                   open         high          low        close     adjclose  \\\n",
      "1997-08-06     2.208333     2.312500     2.187500     2.250000     2.250000   \n",
      "1997-08-07     2.250000     2.260417     2.125000     2.177083     2.177083   \n",
      "1997-08-18     2.052083     2.052083     1.968750     2.041667     2.041667   \n",
      "1997-08-19     2.093750     2.208333     2.052083     2.166667     2.166667   \n",
      "1997-08-21     2.135417     2.171875     2.072917     2.114583     2.114583   \n",
      "...                 ...          ...          ...          ...          ...   \n",
      "2021-02-26  3095.199951  3122.439941  3036.699951  3092.929932  3092.929932   \n",
      "2021-03-02  3143.469971  3163.520020  3087.120117  3094.530029  3094.530029   \n",
      "2021-03-09  3017.989990  3090.959961  3005.149902  3062.850098  3062.850098   \n",
      "2021-03-15  3074.570068  3082.239990  3032.090088  3081.679932  3081.679932   \n",
      "2021-03-31  3064.060059  3119.330078  3062.500000  3094.080078  3094.080078   \n",
      "\n",
      "             volume ticker   adjclose_7  true_adjclose_7  buy_profit  \\\n",
      "1997-08-06  1243200   AMZN    -3.354586         2.114583    0.000000   \n",
      "1997-08-07  2034000   AMZN    -3.505675         2.041667    0.000000   \n",
      "1997-08-18  1784400   AMZN    -3.914773         2.317708   -5.956440   \n",
      "1997-08-19  1003200   AMZN    -3.926589         2.375000   -6.093256   \n",
      "1997-08-21   624000   AMZN    -3.996313         2.354167   -6.110896   \n",
      "...             ...    ...          ...              ...         ...   \n",
      "2021-02-26  4273500   AMZN  3122.840088      3062.850098    0.000000   \n",
      "2021-03-02  2590000   AMZN  3090.805908      3113.590088   -3.724121   \n",
      "2021-03-09  4023500   AMZN  2994.080322      3027.989990    0.000000   \n",
      "2021-03-15  2913600   AMZN  2996.535889      3087.070068  -85.144043   \n",
      "2021-03-31  3093900   AMZN  3011.853271      3379.389893  -82.226807   \n",
      "\n",
      "            sell_profit  \n",
      "1997-08-06     5.604586  \n",
      "1997-08-07     5.682758  \n",
      "1997-08-18     0.000000  \n",
      "1997-08-19     0.000000  \n",
      "1997-08-21     0.000000  \n",
      "...                 ...  \n",
      "2021-02-26   -29.910156  \n",
      "2021-03-02     0.000000  \n",
      "2021-03-09    68.769775  \n",
      "2021-03-15     0.000000  \n",
      "2021-03-31     0.000000  \n",
      "\n",
      "[1193 rows x 11 columns], 3242.0994, 0.46353730092204526)\n"
     ]
    }
   ],
   "source": [
    "print(make_prediction())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
